{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import glob\n",
    "import nibabel as nb\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, wls\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from patsy.contrasts import Treatment\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "import sklearn\n",
    "import statsmodels\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.iolib.table import (SimpleTable, default_txt_fmt)\n",
    "from statsmodels.discrete.discrete_model import Probit, MNLogit\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFdr\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/abhijit/Jyotirmay/my_thesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_feats = ['smoker_former', 'smoker_irregular', 'smoker_non_smoker', 'smoker_regular', 'smoking-packages']\n",
    "bmi_feats = ['bmi-who_normal', 'bmi-who_obesity class I', 'bmi-who_obesity class II', 'bmi-who_obesity class III',\n",
    "            'bmi_numeric', 'bmi-who_pre-obisety']\n",
    "blood_pressure_feats = ['blood-pressure-diastolic', 'blood-pressure-systolic']\n",
    "cholesterol_feats = ['cholesterol-hdl', 'cholesterol-ldl', 'cholesterol-total']\n",
    "mri_feats = ['mri-liver-fat-artifacts', 'mri-liver-fat-lobus-dexter', \n",
    "             'mri-liver-fat-lobus-sinister', 'mri-liver-fat-portal-vein']\n",
    "alcohol_feats = ['alcohol-g/day']\n",
    "hbalc_feats = ['hba1c-mmol/mol', 'hba1c-percentage']\n",
    "medication_feats = ['meds-antidiabetic', 'meds-antihypertensive', 'meds-incretin-mimetics', 'meds-insulin-therapy',\n",
    "                    'meds-lipoprotein-lowering', 'meds-oral-antidiabetic']\n",
    "triglyceride = ['triglyceride']\n",
    "hypertension = ['hypertension']\n",
    "basic_feats = ['age', 'height', 'sex', 'weight']\n",
    "\n",
    "vols_feat = ['seg_liver', 'seg_spleen']\n",
    "spleen_sample_cols = ['0_spleen','1_spleen','2_spleen','3_spleen','4_spleen','5_spleen','6_spleen','7_spleen','8_spleen','9_spleen']\n",
    "liver_sample_cols = ['0_liver','1_liver','2_liver','3_liver','4_liver','5_liver','6_liver','7_liver','8_liver','9_liver']\n",
    "\n",
    "feats_from_paper_for_group_test = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status_0', 'diabetes_status_1', 'diabetes_status_2'], ['hypertension'], ['triglyceride'],\n",
    "             ['cholesterol_hdl', 'cholesterol_ldl'],\n",
    "             ['mri_liver_fat_artifacts', 'mri_liver_fat_lobus_dexter', \n",
    "              'mri_liver_fat_lobus_sinister', 'mri_liver_fat_portal_vein'],\n",
    "             ['meds_lipoprotein_lowering'],\n",
    "             ['smoker_former', 'smoker_non_smoker', 'smoker_regular']]\n",
    "\n",
    "feats_from_paper_for_group_test_no_categorisation = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status'], ['hypertension'], ['triglyceride'],\n",
    "             ['cholesterol_hdl', 'cholesterol_ldl'],\n",
    "             ['mri_liver_fat_artifacts', 'mri_liver_fat_lobus_dexter', \n",
    "              'mri_liver_fat_lobus_sinister', 'mri_liver_fat_portal_vein'],\n",
    "             ['meds_lipoprotein_lowering'],\n",
    "             ['smoker_former', 'smoker_non_smoker', 'smoker_regular']]\n",
    "\n",
    "feats_from_paper_for_individual_test = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status_0', 'diabetes_status_1', 'diabetes_status_2'], ['hypertension'], ['triglyceride'],\n",
    "             ['blood_pressure_diastolic', 'blood_pressure_systolic'],\n",
    "             ['cholesterol_hdl', 'cholesterol_ldl', 'cholesterol_total'],\n",
    "             ['mri_liver_fat_artifacts', 'mri_liver_fat_lobus_dexter', \n",
    "              'mri_liver_fat_lobus_sinister', 'mri_liver_fat_portal_vein'],\n",
    "             ['meds_lipoprotein_lowering', 'meds_antihypertensive'],\n",
    "             ['smoker_former', 'smoker_non_smoker', 'smoker_regular'], ['alcohol_g_day']]\n",
    "\n",
    "feats_from_paper_for_individual_test_ukb = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status']]\n",
    "\n",
    "paper_link = 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0177154&type=printable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merged_feats_path = [\n",
    "#     {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_concat_report_final.csv'},\n",
    "    {'full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_concat_report_final.csv'},\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_concat_report_final.csv'}, \n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_concat_report_final.csv'}, \n",
    "    {'hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_concat_report_final.csv'}\n",
    "]\n",
    "all_dataset_merged_feats_path = [\n",
    "    {'all_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_False_concat_report_final.csv'}, \n",
    "    {'all_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "test_dataset_merged_feats_path = [\n",
    "    {'test_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_False_concat_report_final.csv'}, \n",
    "    {'test_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "all_paths = [\n",
    "    {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_concat_report_final.csv'},\n",
    "    {'full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_concat_report_final.csv'},\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_concat_report_final.csv'}, \n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_concat_report_final.csv'}, \n",
    "    {'hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_concat_report_final.csv'},\n",
    "#     {'all_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_False_concat_report_final.csv'}, \n",
    "#     {'all_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_True_concat_report_final.csv'},\n",
    "#     {'test_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_False_concat_report_final.csv'}, \n",
    "    {'test_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "only_data_paths =  {'test_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_True_concat_report_final.csv'}\n",
    "final_model_report_path = [\n",
    "    {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_final_report.csv'},\n",
    "    {'full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_final_report.csv'},\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_final_report.csv'}, \n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_final_report.csv'}, \n",
    "    {'hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_final_report.csv'}\n",
    "]\n",
    "\n",
    "ukb_paths = [\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_UKB_v2/UKB/10_1573078374.453554_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "fb = 'full_bayesian'\n",
    "fb01 = 'full_bayesian_0dot01'\n",
    "mc = 'MC_dropout_quicknat'\n",
    "pq = 'probabilistic_quicknat'\n",
    "hq = 'hierarchical_quicknat'\n",
    "af = 'all_KORA_processed_False'\n",
    "at = 'all_KORA_processed_True'\n",
    "tf = 'test_KORA_processed_False'\n",
    "tt = 'test_KORA_processed_True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def transform_to_categorical(df, categorical_features_list):\n",
    "    for f in categorical_features_list:\n",
    "        dfDummies = pd.get_dummies(df[f], prefix = f)\n",
    "        df = pd.concat([df, dfDummies], axis=1)\n",
    "    return df\n",
    "\n",
    "def rename(df, cols_map=None):\n",
    "    if cols_map is None:\n",
    "        cols_map =  {'bmi-numeric':'bmi_numeric', 'blood-pressure-diastolic':'blood_pressure_diastolic', 'blood-pressure-systolic':'blood_pressure_systolic',\n",
    "             'cholesterol-hdl':'cholesterol_hdl', 'cholesterol-ldl':'cholesterol_ldl', 'cholesterol-total':'cholesterol_total',\n",
    "             'mri-liver-fat-artifacts':'mri_liver_fat_artifacts', 'mri-liver-fat-lobus-dexter':'mri_liver_fat_lobus_dexter', \n",
    "              'mri-liver-fat-lobus-sinister':'mri_liver_fat_lobus_sinister', 'mri-liver-fat-portal-vein':'mri_liver_fat_portal_vein',\n",
    "             'meds-lipoprotein-lowering':'meds_lipoprotein_lowering', 'meds-antihypertensive':'meds_antihypertensive',\n",
    "              'smoker_non-smoker':'smoker_non_smoker','alcohol-g/day':'alcohol_g_day'}\n",
    "    df.rename(columns=cols_map, inplace=True)\n",
    "    return df\n",
    "\n",
    "def z_score_column_normalise(df, column_list):\n",
    "    normalised_cols_map = {}\n",
    "    for column in column_list:\n",
    "        normalised_cols_map[column] = column+'_normalised'\n",
    "        df[normalised_cols_map[column]] = (df[column] - df[column].mean())/df[column].std(ddof=0)\n",
    "    return df, normalised_cols_map\n",
    "\n",
    "def z_score_group_normalise(df, cols_to_normalise):\n",
    "    normalised_cols_map = {}\n",
    "    group_cols_value = df[cols_to_normalise].values\n",
    "    mean, std = np.mean(group_cols_value), np.std(group_cols_value, ddof=0)\n",
    "    for column in cols_to_normalise:\n",
    "        normalised_cols_map[column] = 'normalised_'+column\n",
    "        df[normalised_cols_map[column]] = (df[column] - mean)/std\n",
    "    return df, normalised_cols_map\n",
    "\n",
    "def pre_process_for_mlm(df, to_be_transpose_cols, value_name):\n",
    "    cols = list(df.columns)\n",
    "    cols_without_tobe_transposed_cols = list(set(cols) - set(to_be_transpose_cols))\n",
    "    df = df.melt(id_vars=cols_without_tobe_transposed_cols, \n",
    "            value_vars=to_be_transpose_cols, \n",
    "            value_name=value_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_diabetes_state(df):\n",
    "    df_normal = df[df['diabetes_status']==0]\n",
    "    df_pre_diabetic = df[df['diabetes_status']==1]\n",
    "    df_diabetic = df[df['diabetes_status']==2]\n",
    "    df_normal_affx = df_normal.rename(columns=lambda x: 'normal_'+x)\n",
    "    df_pre_diabetic_affx = df_pre_diabetic.rename(columns=lambda x: 'pre_diabetic_'+x)\n",
    "    df_diabetic_affx = df_diabetic.rename(columns=lambda x: 'diabetic_'+x)\n",
    "    dfs = pd.concat([df_normal_affx, df_pre_diabetic_affx, df_diabetic_affx])\n",
    "    return dfs\n",
    "\n",
    "def plot_and_ttest(df, cols):\n",
    "    dicts = {}\n",
    "    for col_subset in itertools.combinations(cols, 2):\n",
    "        print(f'{col_subset[0]} vs {col_subset[1]}')\n",
    "        df[list(col_subset)].boxplot(rot=45)\n",
    "        t,p = stats.ttest_ind(df[col_subset[0]].dropna().values, df[col_subset[1]].dropna().values)\n",
    "\n",
    "        print('ttest_score:', t)\n",
    "        print('p_value:', p)\n",
    "        print('\\n')\n",
    "        dicts[f'{col_subset[0]} vs {col_subset[1]}'] = p\n",
    "        plt.show()\n",
    "    return dicts\n",
    "\n",
    "def model_evaluation_matrics(file_paths_dict, cols_to_fetch):\n",
    "    dicts = {}\n",
    "    for model, path in file_paths_dict.items():\n",
    "        df = pd.read_csv(path)\n",
    "        dicts[model] = df[cols_to_fetch].iloc[1:].mean()\n",
    "    return dicts\n",
    "\n",
    "def individual_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex']):\n",
    "    p_values = {}\n",
    "    for f in feats:\n",
    "        try:\n",
    "            features_string = make_feature_string([f], categorical_feats)\n",
    "            fii = ols(f'{target_col} ~ {features_string}', df).fit()\n",
    "            feat_dict = fii.pvalues.to_dict()\n",
    "            coeffs = fii.params\n",
    "        \n",
    "            for k, v in feat_dict.items():\n",
    "                orig_key = k\n",
    "                if k == 'Intercept':\n",
    "                    k = f+'_Intercept'\n",
    "                p_values[k] = v\n",
    "\n",
    "                p_values[k+'_coeff'] = coeffs[orig_key]\n",
    "            p_values['fitting_score'] = fii.rsquared\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "def make_feature_string(feats, categorical_cols=[]):\n",
    "    feat_str = '1+'\n",
    "    for c_col in categorical_cols:\n",
    "        if type(c_col) is tuple:\n",
    "            if c_col[0] not in feats:\n",
    "#                 print(f'{c_col} is not present in given feature list, SKIPPING IT!')\n",
    "                continue\n",
    "            feat_str += f'C({c_col[0]}, Treatment(reference={c_col[1]}))+'\n",
    "            c_col = c_col[0]\n",
    "        else:\n",
    "            if c_col not in feats:\n",
    "#                 print(f'{c_col} is not present in given feature list, SKIPPING IT!')\n",
    "                continue\n",
    "            feat_str += f'C({c_col}, Treatment)+'\n",
    "        feats.remove(c_col)\n",
    "    \n",
    "    other_feats_str = '+'.join(feats)\n",
    "    if other_feats_str is '':\n",
    "        final_feat_str = feat_str[:-1]\n",
    "    else:\n",
    "        final_feat_str = feat_str + other_feats_str\n",
    "\n",
    "    return final_feat_str\n",
    "    \n",
    "\n",
    "def normal_group_fit(df, target_col, features_string):\n",
    "    model = ols(f'{target_col} ~ {features_string}', df).fit()\n",
    "    plot_model_outputs(df['bmi_numeric'].values, df[target_col].values, model, 'OLS')\n",
    "    return model\n",
    "\n",
    "def weighted_group_feats(df, target_col, features_string, alpha_col):\n",
    "    alpha = df[alpha_col].values\n",
    "    model = wls(f'{target_col} ~ {features_string}', df, weights=(1/(1-alpha))).fit()\n",
    "    return model\n",
    "\n",
    "def normal_mixed_effect_model(df, target_col, features_string, group_col, L1_wt=None):\n",
    "    if L1_wt is None:\n",
    "        model = mixedlm(f'{target_col} ~ {features_string}', df, groups=df[group_col]).fit()\n",
    "    else:\n",
    "        model = mixedlm(f'{target_col} ~ {features_string}', df, groups=df[group_col]).fit_regularized(L1_wt=L1_wt)\n",
    "    return model\n",
    "\n",
    "def anova_test(ols_model):\n",
    "    anova_stats = sm.stats.anova_lm(ols_model)\n",
    "    return anova_stats\n",
    "\n",
    "def df_from_nested_dicts(dicts):\n",
    "    df = pd.concat({k+'_'+kk: pd.concat({kk:pd.DataFrame(vv, index=[0]).T}, axis=1) for k, v in dicts.items() for kk, vv in v.items()}, axis=1)\n",
    "    return df\n",
    "\n",
    "def df_from_nested_dicts_group(dicts):\n",
    "    df = pd.concat({k+'_'+kk: pd.concat({kk:pd.DataFrame(vv, index=[0]).T}, axis=1) for k, v in dicts.items() for kk, vv in v.items()}, axis=1)\n",
    "    return df\n",
    "\n",
    "def highlight_significance(df, threshold=0.05):\n",
    "    return df.style.applymap(lambda x: 'background-color : yellow' if x==True or x<threshold else '')\n",
    "\n",
    "def choose_best_features(df, feats, target_col, percentile=50):\n",
    "    X, y = df[feats], df[target_col]\n",
    "    columns = X.columns.values\n",
    "    feat_selection_model = SelectFdr(f_regression, alpha=0.05).fit(X, y)\n",
    "    col_mask = feat_selection_model.get_support()\n",
    "    return columns[col_mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discrete_individual_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex'], is_classification=False):\n",
    "    p_values = {}\n",
    "    for f in feats:\n",
    "        try:\n",
    "            x = df[f]\n",
    "            y = df[target_col]\n",
    "            x = add_constant(x)\n",
    "            model = MNLogit(y, x)\n",
    "            fii = model.fit()\n",
    "            fii_ = fii.get_margeff()\n",
    "            print(fii.summary())\n",
    "            print(fii_.summary())\n",
    "            feat_dict = fii.pvalues.to_dict()\n",
    "            coeffs = fii.params\n",
    "            \n",
    "            for ko, vo in feat_dict.items():\n",
    "                 for k, v in vo.items():\n",
    "                    orig_key = k\n",
    "                    if k == 'const':\n",
    "                        k = f+'_Intercept'\n",
    "                    p_values[str(ko)+'_'+k] = v\n",
    "                    p_values[str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "                \n",
    "            p_values['aic'] = fii.aic\n",
    "            p_values['bic'] = fii.bic\n",
    "        except Exception as e:\n",
    "            print('ERROR:', e)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "def discrete_group_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex'], is_classification=False):\n",
    "    p_values = {}\n",
    "    try:\n",
    "        x = df[feats]\n",
    "        y = df[target_col]\n",
    "        x = add_constant(x)\n",
    "        model = MNLogit(y, x)\n",
    "        fii = model.fit()\n",
    "        fii_ = fii.get_margeff()\n",
    "        print(fii.summary())\n",
    "        print(fii_.summary())\n",
    "        feat_dict = fii.pvalues.to_dict()\n",
    "        coeffs = fii.params\n",
    "\n",
    "        for ko, vo in feat_dict.items():\n",
    "             for k, v in vo.items():\n",
    "                orig_key = k\n",
    "#                 if k == 'const':\n",
    "#                     k = f+'_Intercept'\n",
    "                p_values[str(ko)+'_'+k] = v\n",
    "                p_values[str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "\n",
    "        p_values['aic'] = fii.aic\n",
    "        p_values['bic'] = fii.bic\n",
    "    except Exception as e:\n",
    "        print('ERROR:', e)\n",
    "\n",
    "    return p_values, fii\n",
    "\n",
    "def discrete_weighted_group_feats(df, target_col, feats, alpha_col):\n",
    "    alpha = df[alpha_col].values\n",
    "    x = df[feats]\n",
    "    y = df[target_col]\n",
    "    x = add_constant(x)\n",
    "    model = MNLogit(y, x, weights=(1/(1-alpha))).fit()\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "significance_check = lambda x: False if x>0.05 else True\n",
    "def group_feature_stats(features_string, df, target_col, return_model=False):\n",
    "    p_values, fii = None, None\n",
    "    dicts = {}\n",
    "    try:\n",
    "        model = ols(f'{target_col} ~ {features_string}', df)\n",
    "        fii = model.fit()\n",
    "        p_values = fii.pvalues.to_dict()\n",
    "        coeffs = fii.params.to_dict()\n",
    "        dicts = {}\n",
    "        for k, v in p_values.items():\n",
    "                dicts[k] = v\n",
    "                dicts[k+'_coeff'] = coeffs[k]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if return_model:\n",
    "        return dicts, fii, model\n",
    "    else:\n",
    "        return dicts, fii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_bayesian_0dot01 (148,)\n",
      "MC_dropout_quicknat (150,)\n",
      "probabilistic_quicknat (153,)\n",
      "hierarchical_quicknat (153,)\n",
      "---------------------------------------------\n",
      "Common volumes size: (147,)\n"
     ]
    }
   ],
   "source": [
    "def get_common_vols_based_on_given_col(reference_col='iou_mean', threshold_value=0.51):\n",
    "    common_vols = []\n",
    "    model_merged_feats_path_combined = {key:val for d in model_merged_feats_path for key,val in d.items()}\n",
    "    for key, value in model_merged_feats_path_combined.items():\n",
    "        df = pd.read_csv(value)\n",
    "        df_filter = df[df[reference_col]>threshold_value]\n",
    "        filtered_vols = df_filter.volume_id.values\n",
    "        print(key, filtered_vols.shape)\n",
    "        if len(common_vols) == 0:\n",
    "            common_vols = filtered_vols\n",
    "        else:\n",
    "            common_vols = np.intersect1d(common_vols, filtered_vols)    \n",
    "    return common_vols\n",
    "\n",
    "common_vols = get_common_vols_based_on_given_col()\n",
    "if common_vols.shape[0] < 1:\n",
    "    raise Exception('no common volumes among models')\n",
    "else:\n",
    "    print('---------------------------------------------')\n",
    "    print('Common volumes size:', common_vols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merged_feats_path_combined = {key:val for d in all_paths for key,val in d.items()}\n",
    "only_models_final_report_path = {key:val for d in final_model_report_path for key,val in d.items()}\n",
    "ukb_paths_conbined = {key:val for d in ukb_paths for key,val in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sncc</th>\n",
       "      <th>ged</th>\n",
       "      <th>iou_spleen</th>\n",
       "      <th>iou_liver</th>\n",
       "      <th>dice_spleen</th>\n",
       "      <th>dice_liver</th>\n",
       "      <th>surface_distance_avg_spleen</th>\n",
       "      <th>surface_distance_avg_liver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>full_bayesian</th>\n",
       "      <td>0.604205</td>\n",
       "      <td>0.223997</td>\n",
       "      <td>0.524697</td>\n",
       "      <td>0.668660</td>\n",
       "      <td>0.828703</td>\n",
       "      <td>0.894704</td>\n",
       "      <td>0.809946</td>\n",
       "      <td>0.736798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full_bayesian_0dot01</th>\n",
       "      <td>0.439956</td>\n",
       "      <td>0.195701</td>\n",
       "      <td>0.778342</td>\n",
       "      <td>0.843610</td>\n",
       "      <td>0.876280</td>\n",
       "      <td>0.921408</td>\n",
       "      <td>0.878530</td>\n",
       "      <td>0.817305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MC_dropout_quicknat</th>\n",
       "      <td>0.399954</td>\n",
       "      <td>0.166135</td>\n",
       "      <td>0.821329</td>\n",
       "      <td>0.878295</td>\n",
       "      <td>0.897294</td>\n",
       "      <td>0.937717</td>\n",
       "      <td>0.915982</td>\n",
       "      <td>0.870747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>probabilistic_quicknat</th>\n",
       "      <td>0.163864</td>\n",
       "      <td>0.228308</td>\n",
       "      <td>0.988114</td>\n",
       "      <td>0.992439</td>\n",
       "      <td>0.873666</td>\n",
       "      <td>0.925428</td>\n",
       "      <td>0.875153</td>\n",
       "      <td>0.827462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hierarchical_quicknat</th>\n",
       "      <td>0.187984</td>\n",
       "      <td>0.209171</td>\n",
       "      <td>0.983818</td>\n",
       "      <td>0.988998</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.932802</td>\n",
       "      <td>0.897351</td>\n",
       "      <td>0.854833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sncc       ged  iou_spleen  iou_liver  \\\n",
       "full_bayesian           0.604205  0.223997    0.524697   0.668660   \n",
       "full_bayesian_0dot01    0.439956  0.195701    0.778342   0.843610   \n",
       "MC_dropout_quicknat     0.399954  0.166135    0.821329   0.878295   \n",
       "probabilistic_quicknat  0.163864  0.228308    0.988114   0.992439   \n",
       "hierarchical_quicknat   0.187984  0.209171    0.983818   0.988998   \n",
       "\n",
       "                        dice_spleen  dice_liver  surface_distance_avg_spleen  \\\n",
       "full_bayesian              0.828703    0.894704                     0.809946   \n",
       "full_bayesian_0dot01       0.876280    0.921408                     0.878530   \n",
       "MC_dropout_quicknat        0.897294    0.937717                     0.915982   \n",
       "probabilistic_quicknat     0.873666    0.925428                     0.875153   \n",
       "hierarchical_quicknat      0.883146    0.932802                     0.897351   \n",
       "\n",
       "                        surface_distance_avg_liver  \n",
       "full_bayesian                             0.736798  \n",
       "full_bayesian_0dot01                      0.817305  \n",
       "MC_dropout_quicknat                       0.870747  \n",
       "probabilistic_quicknat                    0.827462  \n",
       "hierarchical_quicknat                     0.854833  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_fetch = ['sncc', 'ged', 'iou_spleen', 'iou_liver', 'dice_spleen',\n",
    "       'dice_liver', 'surface_distance_avg_spleen', 'surface_distance_avg_liver']\n",
    "dicts = model_evaluation_matrics(only_models_final_report_path, cols_to_fetch)\n",
    "df_model_eval = pd.DataFrame.from_dict(dicts)\n",
    "df_model_eval = df_model_eval.T\n",
    "df_model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Stats (with input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "def logistic_regression(features, df, target_col, weights=None, multi_class='ovr'):\n",
    "#     multinomial\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=2)),\n",
    "                      ('linear', LogisticRegression(multi_class=multi_class, solver='newton-cg'))])\n",
    "    x = df[features].values\n",
    "    y = df[target_col].values\n",
    "#     print(x.shape, y.shape)\n",
    "    model = model.fit(x, y)\n",
    "#     print(model.summary())\n",
    "    return model\n",
    "\n",
    "# class Logistic_Regression(linear_model.LogisticRegression):\n",
    "#     \"\"\"\n",
    "#     LinearRegression class after sklearn's, but calculate t-statistics\n",
    "#     and p-values for model coefficients (betas).\n",
    "#     Additional attributes available after .fit()\n",
    "#     are `t` and `p` which are of the shape (y.shape[1], X.shape[1])\n",
    "#     which is (n_features, n_coefs)\n",
    "#     This class sets the intercept to 0 by default, since usually we include it\n",
    "#     in X.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         if not \"fit_intercept\" in kwargs:\n",
    "#             kwargs['fit_intercept'] = False\n",
    "#         super(Logistic_Regression, self)\\\n",
    "#                 .__init__(*args, **kwargs)\n",
    "\n",
    "#     def fit(self, X, y, n_jobs=1):\n",
    "#         self = super(Logistic_Regression, self).fit(X, y, n_jobs)\n",
    "\n",
    "#         sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "#         se = np.array([\n",
    "#             np.sqrt(np.diagonal(sse[i] * np.linalg.inv(np.dot(X.T, X))))\n",
    "#                                                     for i in range(sse.shape[0])\n",
    "#                     ])\n",
    "\n",
    "#         self.t = self.coef_ / se\n",
    "#         self.p = 2 * (1 - stats.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1]))\n",
    "#         return self   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U21') dtype('<U21') dtype('<U21')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f957b4609986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0monly_data_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volume_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'KORA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mrt-image-id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolume_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_vols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U21') dtype('<U21') dtype('<U21')"
     ]
    }
   ],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "best_feats_spleen, best_feats_liver = None, None\n",
    "for key, value in only_data_paths.items():\n",
    "    df = pd.read_csv(value)\n",
    "#     df['volume_id'] = ['KORA']+df['mrt-image-id'].values\n",
    "    print(df.columns)\n",
    "    df = df[df.volume_id.isin(common_vols)]\n",
    "    print(df.shape)\n",
    "    df = rename(df)\n",
    "#     df = transform_to_categorical(df, ['diabetes_status'])\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    dicts[key] = {}\n",
    "    target_col = 'diabetes_status'\n",
    "    p_value_dict = logistic_regression(feats, df, target_col, multi_class='multinomial')\n",
    "#     dicts[key][target_col] = p_value_dict\n",
    "    \n",
    "\n",
    "# p_value_df = df_from_nested_dicts(dicts).T\n",
    "# p_value_df_styler = highlight_significance(p_value_df, threshold=0.01)\n",
    "# p_value_df_styler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group features Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "anova_test_dicts = {}\n",
    "for key, value in model_merged_feats_path_combined.items():\n",
    "#     if 'KORA' in key:\n",
    "#         print('dataset cannot be processed!')\n",
    "#         continue\n",
    "    df = pd.read_csv(value)\n",
    "    df = df[df.volume_id.isin(common_vols)]\n",
    "    print(df.shape)\n",
    "    df = rename(df)\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    dicts[key] = {}\n",
    "    \n",
    "    target_col = 'diabetes_status'\n",
    "    best_feats_spleen = feats \n",
    "    p_value_dict_spleen, model = discrete_group_feature_stats(best_feats_spleen, df, target_col, ['sex'], True)\n",
    "\n",
    "    dicts[key][target_col] = p_value_dict_spleen\n",
    "    \n",
    "    feats_ = feats + [ 'seg_spleen_normalised', 'seg_liver_normalised']\n",
    "    p_value_dict_spleen, model = discrete_group_feature_stats(feats_, df, target_col, ['sex'], True)\n",
    "\n",
    "    dicts[key][target_col+'_with_seg_volumes'] = p_value_dict_spleen\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularised group feat stats test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "anova_test_dicts = {}\n",
    "for key, value in model_merged_feats_path_combined.items():\n",
    "    if 'KORA' in key:\n",
    "#         print('dataset cannot be processed!')\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(value)\n",
    "    df = rename(df)\n",
    "    df = transform_to_categorical(df, ['diabetes_status', 'sex'])\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    dicts[key] = {}\n",
    "    anova_test_dicts[key] = {}\n",
    "    \n",
    "    target_col = 'diabetes_status'\n",
    "    best_feats_spleen = feats\n",
    "    feature_string =  make_feature_string(list(best_feats_spleen), [ 'sex'])\n",
    "\n",
    "    model = discrete_weighted_group_feats(df, target_col, feats , 'iou_spleen')\n",
    "    feat_dict = model.pvalues.to_dict()\n",
    "    coeffs = model.params\n",
    "    dicts[key][target_col] = {}\n",
    "    for ko, vo in feat_dict.items():\n",
    "             for k, v in vo.items():\n",
    "                orig_key = k\n",
    "#                 if k == 'const':\n",
    "#                     k = f+'_Intercept'\n",
    "                dicts[key][target_col][str(ko)+'_'+k] = v\n",
    "                dicts[key][target_col][str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "\n",
    "    dicts[key][target_col]['aic'] = model.aic\n",
    "    dicts[key][target_col]['bic'] = model.bic\n",
    "    \n",
    "    feats_ = feats + [ 'seg_spleen_normalised', 'seg_liver_normalised']\n",
    "    print(feats_)\n",
    "    model = discrete_weighted_group_feats(df, target_col, feats_ , 'iou_liver')\n",
    "#     result = anova_test(model)\n",
    "#     dicts[key][target_col] = model.pvalues.to_dict()\n",
    "    feat_dict = model.pvalues.to_dict()\n",
    "    coeffs = model.params\n",
    "    dicts[key][target_col+'_seg_volumes'] = {}\n",
    "    for ko, vo in feat_dict.items():\n",
    "             for k, v in vo.items():\n",
    "                orig_key = k\n",
    "#                 if k == 'const':\n",
    "#                     k = f+'_Intercept'\n",
    "                dicts[key][target_col+'_seg_volumes'][str(ko)+'_'+k] = v\n",
    "                dicts[key][target_col+'_seg_volumes'][str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "\n",
    "    dicts[key][target_col+'_seg_volumes']['aic'] = model.aic\n",
    "    dicts[key][target_col+'_seg_volumes']['bic'] = model.bic\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalised Mixed Effect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "for key, value in model_merged_feats_path_combined.items():\n",
    "    if 'KORA' in key:\n",
    "        print('dataset cannot be processed!')\n",
    "        continue\n",
    "    df = pd.read_csv(value)\n",
    "    df = rename(df)\n",
    "    df = df.fillna(0)\n",
    "    df_s = df.copy()\n",
    "    df_l = df.copy()\n",
    "\n",
    "    dicts[key] = {}\n",
    "    \n",
    "    target_col = 'diabetes_status'\n",
    "    df_spleen, spleen_normalised_cols_map = z_score_group_normalise(df, spleen_sample_cols)\n",
    "    df_liver, liver_normalised_cols_map = z_score_group_normalise(df_spleen, liver_sample_cols)\n",
    "    best_feats_spleen = feats + list(spleen_normalised_cols_map.values()) + list(liver_normalised_cols_map.values()) # choose_best_features(df_spleen, feats, target_col)\n",
    "    feature_string =  make_feature_string(list(best_feats_spleen), ['sex'])\n",
    "    p_value_dict_spleen, model = group_feature_stats(feature_string, df_liver, target_col)\n",
    "    dicts[key][target_col] = p_value_dict_spleen\n",
    "    dicts[key][target_col]['fitting_score'] = model.rsquared\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "\n",
    "p_value_df_styler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tenv]",
   "language": "python",
   "name": "conda-env-tenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
