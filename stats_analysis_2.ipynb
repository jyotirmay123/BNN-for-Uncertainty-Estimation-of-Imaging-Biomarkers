{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import glob\n",
    "import nibabel as nb\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, wls\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from patsy.contrasts import Treatment\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.iolib.table import (SimpleTable, default_txt_fmt)\n",
    "from statsmodels.discrete.discrete_model import Probit, MNLogit\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFdr\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/abhijit/Jyotirmay/my_thesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_feats = ['smoker_former', 'smoker_irregular', 'smoker_non_smoker', 'smoker_regular', 'smoking-packages']\n",
    "bmi_feats = ['bmi-who_normal', 'bmi-who_obesity class I', 'bmi-who_obesity class II', 'bmi-who_obesity class III',\n",
    "            'bmi_numeric', 'bmi-who_pre-obisety']\n",
    "blood_pressure_feats = ['blood-pressure-diastolic', 'blood-pressure-systolic']\n",
    "cholesterol_feats = ['cholesterol-hdl', 'cholesterol-ldl', 'cholesterol-total']\n",
    "mri_feats = ['mri-liver-fat-artifacts', 'mri-liver-fat-lobus-dexter', \n",
    "             'mri-liver-fat-lobus-sinister', 'mri-liver-fat-portal-vein']\n",
    "alcohol_feats = ['alcohol-g/day']\n",
    "hbalc_feats = ['hba1c-mmol/mol', 'hba1c-percentage']\n",
    "medication_feats = ['meds-antidiabetic', 'meds-antihypertensive', 'meds-incretin-mimetics', 'meds-insulin-therapy',\n",
    "                    'meds-lipoprotein-lowering', 'meds-oral-antidiabetic']\n",
    "triglyceride = ['triglyceride']\n",
    "hypertension = ['hypertension']\n",
    "basic_feats = ['age', 'height', 'sex', 'weight']\n",
    "\n",
    "vols_feat = ['seg_liver', 'seg_spleen']\n",
    "spleen_sample_cols = ['0_spleen','1_spleen','2_spleen','3_spleen','4_spleen','5_spleen','6_spleen','7_spleen','8_spleen','9_spleen']\n",
    "liver_sample_cols = ['0_liver','1_liver','2_liver','3_liver','4_liver','5_liver','6_liver','7_liver','8_liver','9_liver']\n",
    "\n",
    "feats_from_paper_for_group_test = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status_0', 'diabetes_status_1', 'diabetes_status_2'], ['hypertension'], ['triglyceride'],\n",
    "             ['cholesterol_hdl', 'cholesterol_ldl'],\n",
    "             ['mri_liver_fat_artifacts', 'mri_liver_fat_lobus_dexter', \n",
    "              'mri_liver_fat_lobus_sinister', 'mri_liver_fat_portal_vein'],\n",
    "             ['meds_lipoprotein_lowering'],\n",
    "             ['smoker_former', 'smoker_non_smoker', 'smoker_regular']]\n",
    "\n",
    "feats_from_paper_for_group_test_no_categorisation = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status'], ['hypertension'], ['triglyceride'],\n",
    "             ['cholesterol_hdl', 'cholesterol_ldl'],\n",
    "             ['mri_liver_fat_artifacts', 'mri_liver_fat_lobus_dexter', \n",
    "              'mri_liver_fat_lobus_sinister', 'mri_liver_fat_portal_vein'],\n",
    "             ['meds_lipoprotein_lowering'],\n",
    "             ['smoker_former', 'smoker_non_smoker', 'smoker_regular']]\n",
    "\n",
    "feats_from_paper_for_individual_test = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status_0', 'diabetes_status_1', 'diabetes_status_2'], ['hypertension'], ['triglyceride'],\n",
    "             ['blood_pressure_diastolic', 'blood_pressure_systolic'],\n",
    "             ['cholesterol_hdl', 'cholesterol_ldl', 'cholesterol_total'],\n",
    "             ['mri_liver_fat_artifacts', 'mri_liver_fat_lobus_dexter', \n",
    "              'mri_liver_fat_lobus_sinister', 'mri_liver_fat_portal_vein'],\n",
    "             ['meds_lipoprotein_lowering', 'meds_antihypertensive'],\n",
    "             ['smoker_former', 'smoker_non_smoker', 'smoker_regular'], ['alcohol_g_day']]\n",
    "\n",
    "feats_from_paper_for_individual_test_ukb = [['age', 'sex', 'bmi_numeric'],\n",
    "             ['diabetes_status']]\n",
    "\n",
    "paper_link = 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0177154&type=printable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merged_feats_path = [\n",
    "    {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_concat_report_final.csv'},\n",
    "    {'full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_concat_report_final.csv'},\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_concat_report_final.csv'}, \n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_concat_report_final.csv'}, \n",
    "    {'hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_concat_report_final.csv'}\n",
    "]\n",
    "all_dataset_merged_feats_path = [\n",
    "    {'all_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_False_concat_report_final.csv'}, \n",
    "    {'all_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "test_dataset_merged_feats_path = [\n",
    "    {'test_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_False_concat_report_final.csv'}, \n",
    "    {'test_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "all_paths = [\n",
    "    {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_concat_report_final.csv'},\n",
    "    {'full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_concat_report_final.csv'},\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_concat_report_final.csv'}, \n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_concat_report_final.csv'}, \n",
    "    {'hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_concat_report_final.csv'},\n",
    "#     {'all_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_False_concat_report_final.csv'}, \n",
    "#     {'all_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/all_processed_True_concat_report_final.csv'},\n",
    "#     {'test_KORA_processed_False': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_False_concat_report_final.csv'}, \n",
    "    {'test_KORA_processed_True': '/home/abhijit/Jyotirmay/my_thesis/dataset_groups/whole_body_datasets/KORA/test_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "final_model_report_path = [\n",
    "    {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_final_report.csv'},\n",
    "    {'full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_final_report.csv'},\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_final_report.csv'}, \n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_final_report.csv'}, \n",
    "    {'hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_final_report.csv'}\n",
    "]\n",
    "\n",
    "ukb_paths = [\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_UKB_v2/UKB/10_1573078374.453554_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "fb = 'full_bayesian'\n",
    "fb01 = 'full_bayesian_0dot01'\n",
    "mc = 'MC_dropout_quicknat'\n",
    "pq = 'probabilistic_quicknat'\n",
    "hq = 'hierarchical_quicknat'\n",
    "af = 'all_KORA_processed_False'\n",
    "at = 'all_KORA_processed_True'\n",
    "tf = 'test_KORA_processed_False'\n",
    "tt = 'test_KORA_processed_True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def transform_to_categorical(df, categorical_features_list):\n",
    "    for f in categorical_features_list:\n",
    "        dfDummies = pd.get_dummies(df[f], prefix = f)\n",
    "        df = pd.concat([df, dfDummies], axis=1)\n",
    "    return df\n",
    "\n",
    "def rename(df, cols_map=None):\n",
    "    if cols_map is None:\n",
    "        cols_map =  {'bmi-numeric':'bmi_numeric', 'blood-pressure-diastolic':'blood_pressure_diastolic', 'blood-pressure-systolic':'blood_pressure_systolic',\n",
    "             'cholesterol-hdl':'cholesterol_hdl', 'cholesterol-ldl':'cholesterol_ldl', 'cholesterol-total':'cholesterol_total',\n",
    "             'mri-liver-fat-artifacts':'mri_liver_fat_artifacts', 'mri-liver-fat-lobus-dexter':'mri_liver_fat_lobus_dexter', \n",
    "              'mri-liver-fat-lobus-sinister':'mri_liver_fat_lobus_sinister', 'mri-liver-fat-portal-vein':'mri_liver_fat_portal_vein',\n",
    "             'meds-lipoprotein-lowering':'meds_lipoprotein_lowering', 'meds-antihypertensive':'meds_antihypertensive',\n",
    "              'smoker_non-smoker':'smoker_non_smoker','alcohol-g/day':'alcohol_g_day'}\n",
    "    df.rename(columns=cols_map, inplace=True)\n",
    "    return df\n",
    "\n",
    "def z_score_column_normalise(df, column_list):\n",
    "    normalised_cols_map = {}\n",
    "    for column in column_list:\n",
    "        normalised_cols_map[column] = column+'_normalised'\n",
    "        df[normalised_cols_map[column]] = (df[column] - df[column].mean())/df[column].std(ddof=0)\n",
    "    return df, normalised_cols_map\n",
    "\n",
    "def z_score_group_normalise(df, cols_to_normalise):\n",
    "    normalised_cols_map = {}\n",
    "    group_cols_value = df[cols_to_normalise].values\n",
    "    mean, std = np.mean(group_cols_value), np.std(group_cols_value, ddof=0)\n",
    "    for column in cols_to_normalise:\n",
    "        normalised_cols_map[column] = 'normalised_'+column\n",
    "        df[normalised_cols_map[column]] = (df[column] - mean)/std\n",
    "    return df, normalised_cols_map\n",
    "\n",
    "def pre_process_for_mlm(df, to_be_transpose_cols, value_name):\n",
    "    cols = list(df.columns)\n",
    "    cols_without_tobe_transposed_cols = list(set(cols) - set(to_be_transpose_cols))\n",
    "    df = df.melt(id_vars=cols_without_tobe_transposed_cols, \n",
    "            value_vars=to_be_transpose_cols, \n",
    "            value_name=value_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_diabetes_state(df):\n",
    "    df_normal = df[df['diabetes_status']==0]\n",
    "    df_pre_diabetic = df[df['diabetes_status']==1]\n",
    "    df_diabetic = df[df['diabetes_status']==2]\n",
    "    df_normal_affx = df_normal.rename(columns=lambda x: 'normal_'+x)\n",
    "    df_pre_diabetic_affx = df_pre_diabetic.rename(columns=lambda x: 'pre_diabetic_'+x)\n",
    "    df_diabetic_affx = df_diabetic.rename(columns=lambda x: 'diabetic_'+x)\n",
    "    dfs = pd.concat([df_normal_affx, df_pre_diabetic_affx, df_diabetic_affx])\n",
    "    return dfs\n",
    "\n",
    "def plot_and_ttest(df, cols):\n",
    "    dicts = {}\n",
    "    for col_subset in itertools.combinations(cols, 2):\n",
    "        print(f'{col_subset[0]} vs {col_subset[1]}')\n",
    "        df[list(col_subset)].boxplot(rot=45)\n",
    "        t,p = stats.ttest_ind(df[col_subset[0]].dropna().values, df[col_subset[1]].dropna().values)\n",
    "\n",
    "        print('ttest_score:', t)\n",
    "        print('p_value:', p)\n",
    "        print('\\n')\n",
    "        dicts[f'{col_subset[0]} vs {col_subset[1]}'] = p\n",
    "        plt.show()\n",
    "    return dicts\n",
    "\n",
    "def model_evaluation_matrics(file_paths_dict, cols_to_fetch):\n",
    "    dicts = {}\n",
    "    for model, path in file_paths_dict.items():\n",
    "        df = pd.read_csv(path)\n",
    "        dicts[model] = df[cols_to_fetch].iloc[1:].mean()\n",
    "    return dicts\n",
    "\n",
    "def individual_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex']):\n",
    "    p_values = {}\n",
    "    for f in feats:\n",
    "        try:\n",
    "            features_string = make_feature_string([f], categorical_feats)\n",
    "            fii = ols(f'{target_col} ~ {features_string}', df).fit()\n",
    "            feat_dict = fii.pvalues.to_dict()\n",
    "            coeffs = fii.params\n",
    "        \n",
    "            for k, v in feat_dict.items():\n",
    "                orig_key = k\n",
    "                if k == 'Intercept':\n",
    "                    k = f+'_Intercept'\n",
    "                p_values[k] = v\n",
    "\n",
    "                p_values[k+'_coeff'] = coeffs[orig_key]\n",
    "            p_values['fitting_score'] = fii.rsquared\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "def make_feature_string(feats, categorical_cols=[]):\n",
    "    feat_str = '1+'\n",
    "    for c_col in categorical_cols:\n",
    "        if type(c_col) is tuple:\n",
    "            if c_col[0] not in feats:\n",
    "#                 print(f'{c_col} is not present in given feature list, SKIPPING IT!')\n",
    "                continue\n",
    "            feat_str += f'C({c_col[0]}, Treatment(reference={c_col[1]}))+'\n",
    "            c_col = c_col[0]\n",
    "        else:\n",
    "            if c_col not in feats:\n",
    "#                 print(f'{c_col} is not present in given feature list, SKIPPING IT!')\n",
    "                continue\n",
    "            feat_str += f'C({c_col}, Treatment)+'\n",
    "        feats.remove(c_col)\n",
    "    \n",
    "    other_feats_str = '+'.join(feats)\n",
    "    if other_feats_str is '':\n",
    "        final_feat_str = feat_str[:-1]\n",
    "    else:\n",
    "        final_feat_str = feat_str + other_feats_str\n",
    "\n",
    "    return final_feat_str\n",
    "    \n",
    "\n",
    "def normal_group_fit(df, target_col, features_string):\n",
    "    model = ols(f'{target_col} ~ {features_string}', df).fit()\n",
    "    plot_model_outputs(df['bmi_numeric'].values, df[target_col].values, model, 'OLS')\n",
    "    return model\n",
    "\n",
    "def weighted_group_feats(df, target_col, features_string, alpha_col):\n",
    "    alpha = df[alpha_col].values\n",
    "    model = wls(f'{target_col} ~ {features_string}', df, weights=(1/(1-alpha))).fit()\n",
    "    return model\n",
    "\n",
    "def normal_mixed_effect_model(df, target_col, features_string, group_col, L1_wt=None):\n",
    "    if L1_wt is None:\n",
    "        model = mixedlm(f'{target_col} ~ {features_string}', df, groups=df[group_col]).fit()\n",
    "    else:\n",
    "        model = mixedlm(f'{target_col} ~ {features_string}', df, groups=df[group_col]).fit_regularized(L1_wt=L1_wt)\n",
    "    return model\n",
    "\n",
    "def anova_test(ols_model):\n",
    "    anova_stats = sm.stats.anova_lm(ols_model)\n",
    "    return anova_stats\n",
    "\n",
    "def df_from_nested_dicts(dicts):\n",
    "    df = pd.concat({k+'_'+kk: pd.concat({kk:pd.DataFrame(vv, index=[0]).T}, axis=1) for k, v in dicts.items() for kk, vv in v.items()}, axis=1)\n",
    "    return df\n",
    "\n",
    "def df_from_nested_dicts_group(dicts):\n",
    "    df = pd.concat({k+'_'+kk: pd.concat({kk:pd.DataFrame(vv, index=[0]).T}, axis=1) for k, v in dicts.items() for kk, vv in v.items()}, axis=1)\n",
    "    return df\n",
    "\n",
    "def highlight_significance(df, threshold=0.05):\n",
    "    return df.style.applymap(lambda x: 'background-color : yellow' if x==True or x<threshold else '')\n",
    "\n",
    "def choose_best_features(df, feats, target_col, percentile=50):\n",
    "    X, y = df[feats], df[target_col]\n",
    "    columns = X.columns.values\n",
    "    feat_selection_model = SelectFdr(f_regression, alpha=0.05).fit(X, y)\n",
    "    col_mask = feat_selection_model.get_support()\n",
    "    return columns[col_mask]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "def discrete_individual_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex'], is_classification=False):\n",
    "    p_values = {}\n",
    "    for f in feats:\n",
    "        try:\n",
    "            x = df[f]\n",
    "            y = df[target_col]\n",
    "            x = add_constant(x)\n",
    "            model = MNLogit(y, x)\n",
    "            fii = model.fit()\n",
    "            fii_ = fii.get_margeff()\n",
    "            print(fii.summary())\n",
    "            print(fii_.summary())\n",
    "            feat_dict = fii.pvalues.to_dict()\n",
    "            coeffs = fii.params\n",
    "            \n",
    "            for ko, vo in feat_dict.items():\n",
    "                 for k, v in vo.items():\n",
    "                    orig_key = k\n",
    "                    if k == 'const':\n",
    "                        k = f+'_Intercept'\n",
    "                    p_values[str(ko)+'_'+k] = v\n",
    "                    p_values[str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "                \n",
    "            p_values['aic'] = fii.aic\n",
    "            p_values['bic'] = fii.bic\n",
    "        except Exception as e:\n",
    "            print('ERROR:', e)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "def discrete_group_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex'], is_classification=False):\n",
    "    p_values = {}\n",
    "    try:\n",
    "        x = df[feats]\n",
    "        y = df[target_col]\n",
    "        x = add_constant(x)\n",
    "        model = MNLogit(y, x)\n",
    "        fii = model.fit()\n",
    "        fii_ = fii.get_margeff()\n",
    "        print(fii.summary())\n",
    "        print(fii_.summary())\n",
    "        feat_dict = fii.pvalues.to_dict()\n",
    "        coeffs = fii.params\n",
    "\n",
    "        for ko, vo in feat_dict.items():\n",
    "             for k, v in vo.items():\n",
    "                orig_key = k\n",
    "#                 if k == 'const':\n",
    "#                     k = f+'_Intercept'\n",
    "                p_values[str(ko)+'_'+k] = v\n",
    "                p_values[str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "\n",
    "        p_values['aic'] = fii.aic\n",
    "        p_values['bic'] = fii.bic\n",
    "    except Exception as e:\n",
    "        print('ERROR:', e)\n",
    "\n",
    "    return p_values, fii\n",
    "\n",
    "def discrete_weighted_group_feats(df, target_col, feats, alpha_col):\n",
    "    alpha = df[alpha_col].values\n",
    "    x = df[feats]\n",
    "    y = df[target_col]\n",
    "    x = add_constant(x)\n",
    "    model = MNLogit(y, x, weights=(1/(1-alpha))).fit()\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "significance_check = lambda x: False if x>0.05 else True\n",
    "def group_feature_stats(features_string, df, target_col, return_model=False):\n",
    "    p_values, fii = None, None\n",
    "    dicts = {}\n",
    "    try:\n",
    "        model = ols(f'{target_col} ~ {features_string}', df)\n",
    "        fii = model.fit()\n",
    "        p_values = fii.pvalues.to_dict()\n",
    "        coeffs = fii.params.to_dict()\n",
    "        dicts = {}\n",
    "        for k, v in p_values.items():\n",
    "                dicts[k] = v\n",
    "                dicts[k+'_coeff'] = coeffs[k]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if return_model:\n",
    "        return dicts, fii, model\n",
    "    else:\n",
    "        return dicts, fii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merged_feats_path_combined = {key:val for d in all_paths for key,val in d.items()}\n",
    "only_models_final_report_path = {key:val for d in final_model_report_path for key,val in d.items()}\n",
    "ukb_paths_conbined = {key:val for d in ukb_paths for key,val in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fetch = ['sncc', 'ged', 'iou_spleen', 'iou_liver', 'dice_spleen',\n",
    "       'dice_liver', 'surface_distance_avg_spleen', 'surface_distance_avg_liver']\n",
    "dicts = model_evaluation_matrics(only_models_final_report_path, cols_to_fetch)\n",
    "df_model_eval = pd.DataFrame.from_dict(dicts)\n",
    "df_model_eval = df_model_eval.T\n",
    "df_model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Stats (with input data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group features Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "anova_test_dicts = {}\n",
    "for key, value in model_merged_feats_path_combined.items():\n",
    "#     if 'KORA' in key:\n",
    "#         print('dataset cannot be processed!')\n",
    "#         continue\n",
    "    df = pd.read_csv(value)\n",
    "    df = rename(df)\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    dicts[key] = {}\n",
    "    \n",
    "    target_col = 'diabetes_status'\n",
    "    best_feats_spleen = feats \n",
    "    p_value_dict_spleen, model = discrete_group_feature_stats(best_feats_spleen, df, target_col, ['sex'], True)\n",
    "\n",
    "    dicts[key][target_col] = p_value_dict_spleen\n",
    "    \n",
    "    feats_ = feats + [ 'seg_spleen_normalised', 'seg_liver_normalised']\n",
    "    p_value_dict_spleen, model = discrete_group_feature_stats(feats_, df, target_col, ['sex'], True)\n",
    "\n",
    "    dicts[key][target_col+'_with_seg_volumes'] = p_value_dict_spleen\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularised group feat stats test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "anova_test_dicts = {}\n",
    "for key, value in model_merged_feats_path_combined.items():\n",
    "    if 'KORA' in key:\n",
    "#         print('dataset cannot be processed!')\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(value)\n",
    "    df = rename(df)\n",
    "    df = transform_to_categorical(df, ['diabetes_status', 'sex'])\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    dicts[key] = {}\n",
    "    anova_test_dicts[key] = {}\n",
    "    \n",
    "    target_col = 'diabetes_status'\n",
    "    best_feats_spleen = feats\n",
    "    feature_string =  make_feature_string(list(best_feats_spleen), [ 'sex'])\n",
    "\n",
    "    model = discrete_weighted_group_feats(df, target_col, feats , 'iou_spleen')\n",
    "    feat_dict = model.pvalues.to_dict()\n",
    "    coeffs = model.params\n",
    "    dicts[key][target_col] = {}\n",
    "    for ko, vo in feat_dict.items():\n",
    "             for k, v in vo.items():\n",
    "                orig_key = k\n",
    "#                 if k == 'const':\n",
    "#                     k = f+'_Intercept'\n",
    "                dicts[key][target_col][str(ko)+'_'+k] = v\n",
    "                dicts[key][target_col][str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "\n",
    "    dicts[key][target_col]['aic'] = model.aic\n",
    "    dicts[key][target_col]['bic'] = model.bic\n",
    "    \n",
    "    feats_ = feats + [ 'seg_spleen_normalised', 'seg_liver_normalised']\n",
    "    print(feats_)\n",
    "    model = discrete_weighted_group_feats(df, target_col, feats_ , 'iou_liver')\n",
    "#     result = anova_test(model)\n",
    "#     dicts[key][target_col] = model.pvalues.to_dict()\n",
    "    feat_dict = model.pvalues.to_dict()\n",
    "    coeffs = model.params\n",
    "    dicts[key][target_col+'_seg_volumes'] = {}\n",
    "    for ko, vo in feat_dict.items():\n",
    "             for k, v in vo.items():\n",
    "                orig_key = k\n",
    "#                 if k == 'const':\n",
    "#                     k = f+'_Intercept'\n",
    "                dicts[key][target_col+'_seg_volumes'][str(ko)+'_'+k] = v\n",
    "                dicts[key][target_col+'_seg_volumes'][str(ko)+'_'+k+'_coeff'] = coeffs[ko][orig_key]\n",
    "\n",
    "    dicts[key][target_col+'_seg_volumes']['aic'] = model.aic\n",
    "    dicts[key][target_col+'_seg_volumes']['bic'] = model.bic\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalised Mixed Effect Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = flatten(feats_from_paper_for_group_test_no_categorisation)\n",
    "feats = ['age', 'sex', 'bmi_numeric']\n",
    "dicts = {}\n",
    "for key, value in model_merged_feats_path_combined.items():\n",
    "    if 'KORA' in key:\n",
    "        print('dataset cannot be processed!')\n",
    "        continue\n",
    "    df = pd.read_csv(value)\n",
    "    df = rename(df)\n",
    "    df = df.fillna(0)\n",
    "    df_s = df.copy()\n",
    "    df_l = df.copy()\n",
    "\n",
    "    dicts[key] = {}\n",
    "    \n",
    "    target_col = 'diabetes_status'\n",
    "    df_spleen, spleen_normalised_cols_map = z_score_group_normalise(df, spleen_sample_cols)\n",
    "    df_liver, liver_normalised_cols_map = z_score_group_normalise(df_spleen, liver_sample_cols)\n",
    "    best_feats_spleen = feats + list(spleen_normalised_cols_map.values()) + list(liver_normalised_cols_map.values()) # choose_best_features(df_spleen, feats, target_col)\n",
    "    feature_string =  make_feature_string(list(best_feats_spleen), ['sex'])\n",
    "    p_value_dict_spleen, model = group_feature_stats(feature_string, df_liver, target_col)\n",
    "    dicts[key][target_col] = p_value_dict_spleen\n",
    "    dicts[key][target_col]['fitting_score'] = model.rsquared\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "\n",
    "p_value_df_styler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tenv]",
   "language": "python",
   "name": "conda-env-tenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
