{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import glob\n",
    "import nibabel as nb\n",
    "import itertools\n",
    "import json\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols, wls\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from patsy.contrasts import Treatment\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "from statsmodels.iolib.table import (SimpleTable, default_txt_fmt)\n",
    "from statsmodels.discrete.discrete_model import Probit, MNLogit\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFdr\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "np.random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/abhijit/Jyotirmay/my_thesis'\n",
    "basic_feats = ['age', 'sex', 'bmi_numeric']\n",
    "normalised_basic_feats = ['age_normalised', 'sex', 'bmi_numeric_normalised']\n",
    "spleen_sample_cols = ['0_spleen','1_spleen','2_spleen','3_spleen','4_spleen','5_spleen','6_spleen','7_spleen','8_spleen','9_spleen']\n",
    "liver_sample_cols = ['0_liver','1_liver','2_liver','3_liver','4_liver','5_liver','6_liver','7_liver','8_liver','9_liver']\n",
    "vols_feat = ['seg_liver', 'seg_spleen']\n",
    "iou_feats = ['iou_spleen', 'iou_liver', 'iou_mean']\n",
    "selected_model_feats = basic_feats + spleen_sample_cols + liver_sample_cols + vols_feat + iou_feats + ['volume_id', 'diabetes_status'] #+ ['iou_dot_seg_spleen_normalised', 'iou_dot_seg_liver_normalised']\n",
    "selected_dataset_feats = basic_feats +  ['volume_id', 'diabetes_status'] + vols_feat\n",
    "all_paths = [\n",
    "#     {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v2/KORA/10_1571866968.4002764_concat_report_final.csv'},\n",
    "    {'TRAIN_full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1575638974.364368_concat_report_final.csv'},\n",
    "    {'TRAIN_hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1575682785.7956946_concat_report_final.csv'},   \n",
    "    {'TRAIN_MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1575691492.3282661_concat_report_final.csv'},\n",
    "    {'TRAIN_probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1575685569.8707192_concat_report_final.csv'},\n",
    "#     {'PPUKB_MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_UKB_v2/UKB/0_0.0_concat_report_final_pp.csv'},\n",
    "    {'TEST_full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1572514598.527084_concat_report_final.csv'},\n",
    "    {'TEST_MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_KORA_v2/KORA/10_1572006141.7793334_concat_report_final.csv'}, \n",
    "    {'TEST_probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_KORA_v2/KORA/10_1571996796.7963011_concat_report_final.csv'}, \n",
    "    {'TEST_hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_KORA_v2/KORA/10_1571905560.9377904_concat_report_final.csv'},\n",
    "    {'dataset_KORA_processed': './dataset_groups/whole_body_datasets/KORA/all_processed_True_concat_report_final.csv'},\n",
    "    {'UKB_full_bayesian_0dot01': './projects/full_bayesian/reports/full_bayesian_UKB_v4/UKB/10_1574676555.7948809_concat_report_final_pp_final.csv'},\n",
    "    {'UKB_MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_UKB_v2/UKB/0_0.0_concat_report_final_all.csv'},\n",
    "    {'UKB_probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_UKB_v2/UKB/10_1573834823.1121247_concat_report_final.csv'},\n",
    "    {'UKB_hierarchical_quicknat': './projects/hierarchical_quicknat/reports/hierarchical_quicknat_UKB_v2/UKB/10_1574308007.2486243_concat_report_final.csv'},\n",
    "    {'dataset_UKB_processed': './dataset_groups/whole_body_datasets/UKB/all_processed_True_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "train_report_paths = [\n",
    "    {'full_bayesian': './projects/full_bayesian/reports/full_bayesian_KORA_v4/KORA/10_1575638974.364368_concat_report_final.csv'},\n",
    "    {'dataset_KORA_processed': './dataset_groups/whole_body_datasets/KORA/all_processed_True_concat_report_final.csv'},\n",
    "]\n",
    "\n",
    "ukb_paths = [\n",
    "    {'MC_dropout_quicknat': './projects/MC_dropout_quicknat/reports/MC_dropout_quicknat_UKB_v2/UKB/0_0.0_concat_report_final.csv'},\n",
    "    {'probabilistic_quicknat': './projects/probabilistic_quicknat/reports/probabilistic_quicknat_UKB_v2/UKB/10_1573834823.1121247_concat_report_final.csv'}\n",
    "]\n",
    "\n",
    "model_report_paths = {key:val for d in all_paths for key,val in d.items()}  #all_paths\n",
    "# ukb_model_report_paths = {key:val for d in ukb_paths for key,val in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def transform_to_categorical(df, categorical_features_list):\n",
    "    for f in categorical_features_list:\n",
    "        dfDummies = pd.get_dummies(df[f], prefix = f)\n",
    "        df = pd.concat([df, dfDummies], axis=1)\n",
    "    return df\n",
    "\n",
    "def rename(df, cols_map=None):\n",
    "    if cols_map is None:\n",
    "        cols_map =  {'bmi-numeric':'bmi_numeric', 'blood-pressure-diastolic':'blood_pressure_diastolic', 'blood-pressure-systolic':'blood_pressure_systolic',\n",
    "             'cholesterol-hdl':'cholesterol_hdl', 'cholesterol-ldl':'cholesterol_ldl', 'cholesterol-total':'cholesterol_total',\n",
    "             'mri-liver-fat-artifacts':'mri_liver_fat_artifacts', 'mri-liver-fat-lobus-dexter':'mri_liver_fat_lobus_dexter', \n",
    "              'mri-liver-fat-lobus-sinister':'mri_liver_fat_lobus_sinister', 'mri-liver-fat-portal-vein':'mri_liver_fat_portal_vein',\n",
    "             'meds-lipoprotein-lowering':'meds_lipoprotein_lowering', 'meds-antihypertensive':'meds_antihypertensive',\n",
    "              'smoker_non-smoker':'smoker_non_smoker','alcohol-g/day':'alcohol_g_day'}\n",
    "    df.rename(columns=cols_map, inplace=True)\n",
    "    return df\n",
    "\n",
    "def z_score_column_normalise(df, column_list):\n",
    "    normalised_cols_map = {}\n",
    "    for column in column_list:\n",
    "        normalised_cols_map[column] = column+'_normalised'\n",
    "        df[normalised_cols_map[column]] = (df[column] - df[column].mean())/df[column].std(ddof=1)\n",
    "#         df[normalised_cols_map[column]] = (df[column] - df[column].min())/ (df[column].max() - df[column].min())\n",
    "    return df, normalised_cols_map\n",
    "\n",
    "def z_score_group_normalise(df, cols_to_normalise):\n",
    "    normalised_cols_map = {}\n",
    "    group_cols_value = df[cols_to_normalise].values\n",
    "    mean, std = np.mean(group_cols_value), np.std(group_cols_value, ddof=1)\n",
    "    for column in cols_to_normalise:\n",
    "        normalised_cols_map[column] = 'normalised_'+column\n",
    "        df[normalised_cols_map[column]] = (df[column] - mean)/std\n",
    "    return df, normalised_cols_map\n",
    "\n",
    "def pre_process_for_mlm(df, to_be_transpose_cols, value_name):\n",
    "    cols = list(df.columns)\n",
    "    cols_without_tobe_transposed_cols = list(set(cols) - set(to_be_transpose_cols))\n",
    "    df = df.melt(id_vars=cols_without_tobe_transposed_cols, \n",
    "            value_vars=to_be_transpose_cols, \n",
    "            value_name=value_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "def model_evaluation_matrics(file_paths_dict, cols_to_fetch):\n",
    "    dicts = {}\n",
    "    for model, path in file_paths_dict.items():\n",
    "        if 'dataset' in model:\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        dicts[model] = df[cols_to_fetch].iloc[1:].mean()\n",
    "    return dicts\n",
    "\n",
    "def individual_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex']):\n",
    "    p_values = {}\n",
    "    for f in feats:\n",
    "        try:\n",
    "            features_string = make_feature_string([f], categorical_feats)\n",
    "            fii = ols(f'{target_col} ~ {features_string}', df).fit()\n",
    "            feat_dict = fii.pvalues.to_dict()\n",
    "            coeffs = fii.params\n",
    "        \n",
    "            for k, v in feat_dict.items():\n",
    "                orig_key = k\n",
    "                if k == 'Intercept':\n",
    "                    k = f+'_Intercept'\n",
    "                p_values[k] = v\n",
    "\n",
    "                p_values[k+'_coeff'] = coeffs[orig_key]\n",
    "            p_values['fitting_score'] = fii.rsquared\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    return p_values\n",
    "\n",
    "\n",
    "def make_feature_string(feats, categorical_cols=[]):\n",
    "    feat_str = '1+'\n",
    "    for c_col in categorical_cols:\n",
    "        if type(c_col) is tuple:\n",
    "            if c_col[0] not in feats:\n",
    "#                 print(f'{c_col} is not present in given feature list, SKIPPING IT!')\n",
    "                continue\n",
    "            feat_str += f'C({c_col[0]}, Treatment(reference={c_col[1]}))+'\n",
    "            c_col = c_col[0]\n",
    "        else:\n",
    "            if c_col not in feats:\n",
    "#                 print(f'{c_col} is not present in given feature list, SKIPPING IT!')\n",
    "                continue\n",
    "            feat_str += f'C({c_col}, Treatment)+'\n",
    "        feats.remove(c_col)\n",
    "    \n",
    "    other_feats_str = '+'.join(feats)\n",
    "    if other_feats_str is '':\n",
    "        final_feat_str = feat_str[:-1]\n",
    "    else:\n",
    "        final_feat_str = feat_str + other_feats_str\n",
    "\n",
    "    return final_feat_str\n",
    "    \n",
    "def normal_mixed_effect_model(df, target_col, features_string, group_col, L1_wt=None):\n",
    "    if L1_wt is None:\n",
    "        model = mixedlm(f'{target_col} ~ {features_string}', df, groups=df[group_col]).fit()\n",
    "    else:\n",
    "        model = mixedlm(f'{target_col} ~ {features_string}', df, groups=df[group_col]).fit_regularized(L1_wt=L1_wt)\n",
    "    return model\n",
    "\n",
    "def anova_test(ols_model):\n",
    "    anova_stats = sm.stats.anova_lm(ols_model)\n",
    "    return anova_stats\n",
    "\n",
    "def df_from_nested_dicts(dicts):\n",
    "    df = pd.concat({k+'_'+kk: pd.concat({kk:pd.DataFrame(vv, index=[0]).T}, axis=1) for k, v in dicts.items() for kk, vv in v.items()}, axis=1)\n",
    "    return df\n",
    "\n",
    "def df_from_nested_dicts_group(dicts):\n",
    "    df = pd.concat({k+'_'+kk: pd.concat({kk:pd.DataFrame(vv, index=[0]).T}, axis=1) for k, v in dicts.items() for kk, vv in v.items()}, axis=1)\n",
    "    return df\n",
    "\n",
    "def highlight_significance(df, threshold=0.05):\n",
    "    return df.style.applymap(lambda x: 'background-color : yellow' if x==True or x<threshold else '')\n",
    "\n",
    "\n",
    "def discrete_group_feature_stats(feats, df, target_col, categorical_feats=['diabetes_status', 'sex'], \n",
    "                                 is_classification=False, l1mp=0.01):\n",
    "    p_values = {}\n",
    "#     try:\n",
    "#             features_string = f'1+C({f}, Treatment)' if f in categorical_feats else f'1+{f}'\n",
    "#         df['bmi_2'] = df['bmi_numeric'] ** 2\n",
    "#         feats = feats + ['bmi_2']\n",
    "    x = df[feats]\n",
    "    y = df[target_col]\n",
    "\n",
    "    x = add_constant(x)\n",
    "    model = Probit(y, x)\n",
    "    fii = model.fit_regularized(alpha=l1mp)\n",
    "    predicted = fii.predict(x)\n",
    "    feat_dict = fii.pvalues.to_dict()\n",
    "    coeffs = fii.params\n",
    "\n",
    "    for k, v in feat_dict.items():\n",
    "        p_values[k] = v\n",
    "        p_values[k+'_coeff'] = coeffs[k]\n",
    "\n",
    "    p_values['aic'] = fii.aic\n",
    "    p_values['bic'] = fii.bic\n",
    "    p_values['psuedo_r2'] = fii.prsquared\n",
    "#     except Exception as e:\n",
    "#         print('ERROR:', e)\n",
    "\n",
    "    return p_values, fii, (y, predicted)\n",
    "\n",
    "# def weighted_group_feats(df, target_col, features_string, alpha_col):\n",
    "#     alpha = df[alpha_col].values\n",
    "#     model = wls(f'{target_col} ~ {features_string}', df, weights=(1/(1-alpha))).fit()\n",
    "#     return model\n",
    "\n",
    "def discrete_weighted_group_feats(df, target_col, feats, alpha_col, l1mp=0.01):\n",
    "    p_values = {}\n",
    "    alpha = df[alpha_col].values\n",
    "#     df['bmi_2'] = df['bmi_numeric'] ** 2\n",
    "#     feats = feats + ['bmi_2']\n",
    "    x = df[feats]\n",
    "    y = df[target_col]\n",
    "    \n",
    "    x = add_constant(x)\n",
    "    fii = sm.GLM(y, x, family=sm.families.Binomial(sm.families.links.probit), missing='drop', var_weights=alpha).fit_regularized(alpha=l1mp*(1/alpha))\n",
    "    predicted = fii.predict(x)\n",
    "#     feat_dict = fii.pvalues.to_dict()\n",
    "#     coeffs = fii.params\n",
    "\n",
    "#     for k, v in feat_dict.items():\n",
    "#         p_values[k] = v\n",
    "#         p_values[k+'_coeff'] = coeffs[k]\n",
    "\n",
    "#     p_values['aic'] = fii.aic\n",
    "#     p_values['bic'] = fii.bic\n",
    "#     sst_val = sum(map(lambda x: np.power(x,2),y-np.mean(y))) \n",
    "#     sse_val = sum(map(lambda x: np.power(x,2),fii.resid_response)) \n",
    "#     r2 = 1-(sse_val/sst_val)\n",
    "#     p_values['psuedo_r2'] = r2\n",
    "    return p_values, fii, (y, predicted)\n",
    "\n",
    "def get_pvs(lm, X, y):\n",
    "    params = np.append(lm.intercept_,lm.coef_)\n",
    "    predictions = lm.predict(X)\n",
    "\n",
    "    newX = pd.DataFrame({\"Constant\":np.ones(len(X))}).join(pd.DataFrame(X))\n",
    "    MSE = (sum((y-predictions)**2))/(len(newX)-len(newX.columns))\n",
    "\n",
    "    # Note if you don't want to use a DataFrame replace the two lines above with\n",
    "    # newX = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    # MSE = (sum((y-predictions)**2))/(len(newX)-len(newX[0]))\n",
    "\n",
    "    var_b = MSE*(np.linalg.inv(np.dot(newX.T,newX)).diagonal())\n",
    "    sd_b = np.sqrt(var_b)\n",
    "    ts_b = params/ sd_b\n",
    "\n",
    "    p_values =[2*(1-stats.t.cdf(np.abs(i),(len(newX)-1))) for i in ts_b]\n",
    "\n",
    "    sd_b = np.round(sd_b,3)\n",
    "    ts_b = np.round(ts_b,3)\n",
    "    p_values = np.round(p_values,3)\n",
    "    params = np.round(params,4)\n",
    "\n",
    "    myDF3 = pd.DataFrame()\n",
    "    myDF3[\"Coefficients\"],myDF3[\"Standard Errors\"],myDF3[\"t values\"],myDF3[\"Probabilites\"] = [params,sd_b,ts_b,p_values]\n",
    "    print(myDF3)\n",
    "    return myDF3\n",
    "    \n",
    "def normal_group_fit(df, target_col, features_string, feats = None):\n",
    "    p_values = {}\n",
    "#     fii = ols(f'{target_col} ~ {features_string}', df).fit()\n",
    "    X = df[feats].values\n",
    "    y = df[target_col].values\n",
    "    fii = LinearRegression().fit(X, y)\n",
    "    fii_pvalues = get_pvs(fii, X, y)\n",
    "    \n",
    "    \n",
    "\n",
    "#     predicted = fii.predict(X)\n",
    "#     feat_dict = fii_pvalues.to_dict()\n",
    "#     coeffs = feat_dict['Coefficients']\n",
    "\n",
    "#     for k, v in feat_dict.items():\n",
    "#         p_values[k] = v\n",
    "#         p_values[k+'_coeff'] = coeffs[k]\n",
    "\n",
    "#     p_values['aic'] = fii.aic\n",
    "#     p_values['bic'] = fii.bic\n",
    "#     p_values['psuedo_r2'] = fii.rsquared\n",
    "#     return p_values, fii, (y, predicted)\n",
    "\n",
    "def weighted_group_feats(df, target_col, features_string, alpha_col, feats=None):\n",
    "    p_values = {}\n",
    "    alpha = df[alpha_col].values\n",
    "#     fii = wls(f'{target_col} ~ {features_string}', df, weights=alpha).fit()\n",
    "#     y = df[target_col].values\n",
    "    X = df[feats].values\n",
    "    y = df[target_col].values\n",
    "    fii = LinearRegression().fit(X, y, sample_weight=alpha)\n",
    "    \n",
    "    predicted = fii.predict(df)\n",
    "    feat_dict = fii.pvalues.to_dict()\n",
    "    coeffs = fii.params\n",
    "    \n",
    "    for k, v in feat_dict.items():\n",
    "        p_values[k] = v\n",
    "        p_values[k+'_coeff'] = coeffs[k]\n",
    "\n",
    "    p_values['aic'] = fii.aic\n",
    "    p_values['bic'] = fii.bic\n",
    "    p_values['psuedo_r2'] = fii.rsquared\n",
    "    return p_values, fii, (y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_iou(df):\n",
    "    for iou_col in ['iou_spleen', 'iou_liver', 'iou_mean']:\n",
    "        iou = df[iou_col]\n",
    "#         iou = (iou - iou.mean())/iou.std(ddof=0)\n",
    "        iou = (iou - iou.min()) / (iou.max() - iou.min())\n",
    "        df[f'{iou_col}_normalised'] = iou\n",
    "#     df['iou_mean_normalised'] = (df['iou_spleen_normalised'] + df['iou_liver_normalised']) / 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf(good_pdf, bad_pdf, ax):\n",
    "    ax.fill(x, good_pdf, \"g\", alpha=0.5)\n",
    "    ax.fill(x, bad_pdf,\"r\", alpha=0.5)\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,5])\n",
    "    ax.set_title(\"Probability Distribution\", fontsize=14)\n",
    "    ax.set_ylabel('Counts', fontsize=12)\n",
    "    ax.set_xlabel('P(X=\"bad\")', fontsize=12)\n",
    "    ax.legend([\"good\",\"bad\"])\n",
    "\n",
    "def auc_roc(y_yp, title):\n",
    "    y, predicted = y_yp\n",
    "    y_p = np.where(predicted > 0.5, 1, 0)\n",
    "    labels = [0, 1]\n",
    "    y_1_mask = np.where(y==1, True, False)\n",
    "    y_0_mask = np.where(y==0, True, False)\n",
    "    xs = [predicted[y_0_mask], predicted[y_1_mask]]\n",
    "\n",
    "    fig, ax0 = plt.subplots(nrows=1, ncols=1)\n",
    "    colors = ['red','blue']\n",
    "    ax0.hist(xs, 10, normed=1, histtype='bar', color=colors, label=labels)\n",
    "    ax0.legend(prop={'size': 10})\n",
    "    ax0.set_title('bars with legend')\n",
    "    plt.show()\n",
    "    \n",
    "   \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, predicted, pos_label=1)\n",
    "    auc_score = metrics.roc_auc_score(y, predicted)\n",
    " \n",
    "#     f1_score = metrics.f1_score(y, y_p, labels=labels)\n",
    "    print(f'{title}: auc_score: {auc_score}')\n",
    "#     plt.scatter(predicted, y)\n",
    "#     plt.show()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "#     print(list(y))\n",
    "#     print(predicted)\n",
    "    \n",
    "#     print(y_p)\n",
    "    \n",
    "    cm = confusion_matrix(y, y_p, labels)\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     cax = ax.matshow(cm)\n",
    "#     plt.title('Confusion matrix of the classifier')\n",
    "#     fig.colorbar(cax)\n",
    "#     ax.set_xticklabels([''] + labels)\n",
    "#     ax.set_yticklabels([''] + labels)\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('True')\n",
    "#     plt.show()\n",
    "    \n",
    "#     unique_elements, counts_elements = np.unique(predicted, return_counts=True)\n",
    "#     plt.hist(predicted, bins=20)\n",
    "#     plt.bar(unique_elements, counts_elements)\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(disp)\n",
    "#     disp.ax_.set_title(title)\n",
    "\n",
    "#     print(title)\n",
    "#     print(disp.confusion_matrix)\n",
    "#     print(f'{title}:::  fpr: {fpr}, tpr: {tpr}, threshold: {thresholds}')\n",
    "    return auc_score, 1\n",
    "\n",
    "def regression_plot(y_yp, title=''):\n",
    "    y, predicted = y_yp\n",
    "    print(title)\n",
    "    plt.scatter(predicted, y)\n",
    "    plt.show()\n",
    "    \n",
    "def random_forest_evaluations(df, target_col, feats):\n",
    "    y = df[target_col]\n",
    "    x = df[feats]\n",
    "    kfold_rf = model_selection.KFold(n_splits=10, random_state=10)\n",
    "    model_rf = RandomForestClassifier(n_estimators=100, max_features=3)\n",
    "    results_rf = model_selection.cross_val_score(model_rf, x, y, cv=kfold_rf)\n",
    "    print('Random Forest Out:', results_rf.mean())\n",
    "    return results_rf.mean()\n",
    "\n",
    "def gradient_boosting_evaluations(feats, df, target_col, categorical_feats=['diabetes_status', 'sex'], \n",
    "                                 is_classification=False, l1mp=0.01):\n",
    "    y = df[target_col]\n",
    "    x = df[feats]\n",
    "    x = add_constant(x)\n",
    "    \n",
    "#     kfold_rf = model_selection.KFold(n_splits=10, random_state=10)\n",
    "#     model_rf = RandomForestClassifier(n_estimators=10)\n",
    "#     results_rf = model_selection.cross_val_score(model_rf, x, y, cv=kfold_rf)\n",
    "#     print('Gradient Boosting Out:', results_rf.mean())\n",
    "    \n",
    "#     auc, _ = auc_roc((y, y_p), 'ensemble')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    random_classifier = RandomForestClassifier()\n",
    "    max_feats = x.shape[1]\n",
    "    parameters = { 'max_features':[max_feats],'n_estimators':[500],'min_samples_leaf': [10,50,100,200,500]}\n",
    "\n",
    "    random_grid = GridSearchCV(random_classifier, parameters, cv = 6)\n",
    "    model_gb_fitted = random_grid.fit(x, y)\n",
    "    y_p = model_gb_fitted.predict(x)\n",
    "    \n",
    "    return {}, model_gb_fitted, (y, y_p)\n",
    "\n",
    "def weighted_gradient_boosting_evaluations(df, target_col, feats, alpha_col, l1mp=0.01):\n",
    "    y = df[target_col]\n",
    "    x = df[feats]\n",
    "    x = add_constant(x)\n",
    "    \n",
    "    alpha = df[alpha_col].values\n",
    "    \n",
    "#     kfold_rf = model_selection.KFold(n_splits=10, random_state=10)\n",
    "#     model_rf = RandomForestClassifier(n_estimators=100)\n",
    "#     results_rf = model_selection.cross_val_score(model_rf, x, y, cv=kfold_rf)\n",
    "#     print('Gradient Boosting Out:', results_rf.mean())\n",
    "    random_classifier = RandomForestClassifier()\n",
    "    max_feats = x.shape[1]\n",
    "    parameters = { 'max_features':[max_feats],'n_estimators':[500],'min_samples_leaf': [10,50,100,200,500]}\n",
    "\n",
    "    random_grid = GridSearchCV(random_classifier, parameters, cv = 6)\n",
    "    model_gb_fitted = random_grid.fit(x, y, sample_weight=alpha)\n",
    "    y_p = model_gb_fitted.predict(x)\n",
    "#     auc, _ = auc_roc((y, y_p), 'ensemble')\n",
    "    \n",
    "    return {}, model_gb_fitted, (y, y_p)\n",
    "\n",
    "def bagging_evaluations(df, target_col, feats):\n",
    "    y = df[target_col]\n",
    "    x = df[feats]\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=10)\n",
    "    model_1 = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=10)\n",
    "    results_1 = model_selection.cross_val_score(model_1, x, y, cv=kfold)\n",
    "    print('Bagging Out:', results_1.mean())\n",
    "    return results_1.mean()\n",
    "\n",
    "def sgd_evaluator(df, target_col, feats):\n",
    "    y = df[target_col]\n",
    "    x = df[feats]\n",
    "    kfold_sgb = model_selection.KFold(n_splits=10, random_state=10)\n",
    "    model_sgb = GradientBoostingClassifier(n_estimators=100, random_state=10)\n",
    "    results_sgb = model_selection.cross_val_score(model_sgb, x, y, cv=kfold_sgb)\n",
    "    \n",
    "    y_p = model_sgb.fit(x, y).predict(x)\n",
    "    print('model score: ', model_sgb.score(x, y))\n",
    "    auc_roc((y, y_p), 'sgd')\n",
    "    print('Stochastic Gradient out:', results_sgb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return results_sgb.mean()\n",
    "\n",
    "def voting_classifier_evaluator(df, target_col, feats, weight_col=None, ensemble=None):\n",
    "    y = df[target_col]\n",
    "#     feats = ['age', 'bmi_numeric']\n",
    "    if weight_col is None:\n",
    "        x = df[feats]\n",
    "        weights = None\n",
    "    else:\n",
    "        x = df[feats]\n",
    "        weights = df[weight_col].values\n",
    "    \n",
    "    x = add_constant(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = x, x, y, y #train_test_split(x, y, test_size=0.33, random_state=10)\n",
    "\n",
    "   \n",
    "    if ensemble is None:\n",
    "        estimators = []\n",
    "    \n",
    "#         mod_rf = RandomForestClassifier(n_estimators=100, max_features=3)\n",
    "#         estimators.append(('rf', mod_rf))\n",
    "        mod_bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=10)\n",
    "        estimators.append(('bagging', mod_bagging))\n",
    "        mod_sgd = GradientBoostingClassifier(n_estimators=100, random_state=10)\n",
    "        estimators.append(('sgd', mod_sgd))\n",
    "        mod_lr = LogisticRegression()\n",
    "        estimators.append(('logistic', mod_lr))\n",
    "        mod_dt = DecisionTreeClassifier()\n",
    "        estimators.append(('cart', mod_dt))\n",
    "        mod_sv = SVC()\n",
    "        estimators.append(('svm', mod_sv))\n",
    "      \n",
    "        ensemble = VotingClassifier(estimators)\n",
    "#         print(X_train.columns)\n",
    "        ensemble.fit(X_train, y_train, sample_weight=weights)\n",
    "    else:\n",
    "       \n",
    "        X_train, X_test, y_train, y_test = x, x, y, y\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 1, figsize=(14, 6))\n",
    "#     if weights is None:\n",
    "#         weights = np.ones(len(X_train))\n",
    "#     plot_decision_function(ensemble, weights, axes, title, X_train.values, y_train.values)\n",
    "#     print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "#         print(ensemble)\n",
    "#     auc_roc((y_train, ensemble.predict(X_train)), 'ensemble')\n",
    "#     print('ensemble score train set: ',ensemble.score(X_train, y_train))\n",
    "\n",
    "#     print('here', weights.shape, ensemble.score(X_test, y_test, weights))\n",
    "#     print('here2', ensemble.score(X_test, y_test))\n",
    "    print(X_test.iloc[2])\n",
    "    print(ensemble.predict(X_test), y_test.values)\n",
    "\n",
    "    auc, _ = auc_roc((y_test, ensemble.predict(X_test)), 'ensemble')\n",
    "#     print('ensemble score test set: ',ensemble.score(X_test, y_test))\n",
    "#      kfold_vc = model_selection.KFold(n_splits=10, random_state=10)\n",
    "#     results_vc = model_selection.cross_val_score(ensemble, X_test, y_test, cv=kfold_vc)\n",
    "#     print('Voting Classifier out many mean:', results_vc.mean())\n",
    "# \n",
    "    return 1, 1, ensemble, auc\n",
    "\n",
    "def plot_decision_function(classifier, sample_weight, axis, title, X, y):\n",
    "    # plot the decision function\n",
    "    xx, yy = np.meshgrid(np.linspace(-4, 5, 500), np.linspace(-4, 5, 500))\n",
    "\n",
    "    Z = classifier.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    axis.contourf(xx, yy, Z, alpha=0.75, cmap=plt.cm.bone)\n",
    "    axis.scatter(X[:, 0], X[:, 1], c=y, s=100 * sample_weight, alpha=0.9,\n",
    "                 cmap=plt.cm.bone, edgecolors='black')\n",
    "\n",
    "    axis.axis('off')\n",
    "    axis.set_title(title)\n",
    "    \n",
    "def aggregate_model_outputs(df, target_col, feats, dicts, model, key, ensemble_model=None, weight_col=None):\n",
    "#     dicts['rf'] = random_forest_evaluations(df, target_col, feats)\n",
    "#     dicts[model][key]['bagging'] = bagging_evaluations(df, target_col, feats)\n",
    "#     dicts[model][key]['sgd'] = sgd_evaluator(df, target_col, feats)\n",
    "#     df['bmi_2'] = df['bmi_numeric'] **2\n",
    "#     feats = feats + ['bmi_2']\n",
    "    dicts[model][key]['v_scoring'],dicts[model][key]['v_scoring_with_weight'], ensemble_model, dicts[model][key]['v_auc'] = voting_classifier_evaluator(df, target_col, feats, weight_col, ensemble_model)\n",
    "    \n",
    "    return dicts, ensemble_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sncc</th>\n",
       "      <th>ged</th>\n",
       "      <th>iou_spleen</th>\n",
       "      <th>iou_liver</th>\n",
       "      <th>dice_spleen</th>\n",
       "      <th>dice_liver</th>\n",
       "      <th>surface_distance_avg_spleen</th>\n",
       "      <th>surface_distance_avg_liver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRAIN_full_bayesian_0dot01</th>\n",
       "      <td>0.416059</td>\n",
       "      <td>0.155863</td>\n",
       "      <td>0.847247</td>\n",
       "      <td>0.877531</td>\n",
       "      <td>0.913438</td>\n",
       "      <td>0.939127</td>\n",
       "      <td>0.938857</td>\n",
       "      <td>0.866480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_hierarchical_quicknat</th>\n",
       "      <td>0.254787</td>\n",
       "      <td>0.142976</td>\n",
       "      <td>0.991133</td>\n",
       "      <td>0.992448</td>\n",
       "      <td>0.930222</td>\n",
       "      <td>0.952808</td>\n",
       "      <td>0.966050</td>\n",
       "      <td>0.928719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_MC_dropout_quicknat</th>\n",
       "      <td>0.451659</td>\n",
       "      <td>0.121835</td>\n",
       "      <td>0.878469</td>\n",
       "      <td>0.903837</td>\n",
       "      <td>0.931591</td>\n",
       "      <td>0.955732</td>\n",
       "      <td>0.969341</td>\n",
       "      <td>0.940351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRAIN_probabilistic_quicknat</th>\n",
       "      <td>0.222936</td>\n",
       "      <td>0.136543</td>\n",
       "      <td>0.992391</td>\n",
       "      <td>0.994402</td>\n",
       "      <td>0.936553</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.975707</td>\n",
       "      <td>0.929685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_full_bayesian_0dot01</th>\n",
       "      <td>0.440058</td>\n",
       "      <td>0.195726</td>\n",
       "      <td>0.778430</td>\n",
       "      <td>0.843838</td>\n",
       "      <td>0.876213</td>\n",
       "      <td>0.921414</td>\n",
       "      <td>0.878335</td>\n",
       "      <td>0.817338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_MC_dropout_quicknat</th>\n",
       "      <td>0.400336</td>\n",
       "      <td>0.166126</td>\n",
       "      <td>0.821658</td>\n",
       "      <td>0.878743</td>\n",
       "      <td>0.897251</td>\n",
       "      <td>0.937764</td>\n",
       "      <td>0.915783</td>\n",
       "      <td>0.871014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_probabilistic_quicknat</th>\n",
       "      <td>0.164762</td>\n",
       "      <td>0.228213</td>\n",
       "      <td>0.988126</td>\n",
       "      <td>0.992441</td>\n",
       "      <td>0.873734</td>\n",
       "      <td>0.925382</td>\n",
       "      <td>0.875181</td>\n",
       "      <td>0.827286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEST_hierarchical_quicknat</th>\n",
       "      <td>0.188499</td>\n",
       "      <td>0.209206</td>\n",
       "      <td>0.983803</td>\n",
       "      <td>0.989027</td>\n",
       "      <td>0.883031</td>\n",
       "      <td>0.932817</td>\n",
       "      <td>0.897130</td>\n",
       "      <td>0.854920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UKB_full_bayesian_0dot01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.683044</td>\n",
       "      <td>0.746261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UKB_MC_dropout_quicknat</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707228</td>\n",
       "      <td>0.777343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UKB_probabilistic_quicknat</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965202</td>\n",
       "      <td>0.980590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UKB_hierarchical_quicknat</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935690</td>\n",
       "      <td>0.939154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sncc       ged  iou_spleen  iou_liver  \\\n",
       "TRAIN_full_bayesian_0dot01    0.416059  0.155863    0.847247   0.877531   \n",
       "TRAIN_hierarchical_quicknat   0.254787  0.142976    0.991133   0.992448   \n",
       "TRAIN_MC_dropout_quicknat     0.451659  0.121835    0.878469   0.903837   \n",
       "TRAIN_probabilistic_quicknat  0.222936  0.136543    0.992391   0.994402   \n",
       "TEST_full_bayesian_0dot01     0.440058  0.195726    0.778430   0.843838   \n",
       "TEST_MC_dropout_quicknat      0.400336  0.166126    0.821658   0.878743   \n",
       "TEST_probabilistic_quicknat   0.164762  0.228213    0.988126   0.992441   \n",
       "TEST_hierarchical_quicknat    0.188499  0.209206    0.983803   0.989027   \n",
       "UKB_full_bayesian_0dot01           NaN       NaN    0.683044   0.746261   \n",
       "UKB_MC_dropout_quicknat            NaN       NaN    0.707228   0.777343   \n",
       "UKB_probabilistic_quicknat         NaN       NaN    0.965202   0.980590   \n",
       "UKB_hierarchical_quicknat          NaN       NaN    0.935690   0.939154   \n",
       "\n",
       "                              dice_spleen  dice_liver  \\\n",
       "TRAIN_full_bayesian_0dot01       0.913438    0.939127   \n",
       "TRAIN_hierarchical_quicknat      0.930222    0.952808   \n",
       "TRAIN_MC_dropout_quicknat        0.931591    0.955732   \n",
       "TRAIN_probabilistic_quicknat     0.936553    0.953047   \n",
       "TEST_full_bayesian_0dot01        0.876213    0.921414   \n",
       "TEST_MC_dropout_quicknat         0.897251    0.937764   \n",
       "TEST_probabilistic_quicknat      0.873734    0.925382   \n",
       "TEST_hierarchical_quicknat       0.883031    0.932817   \n",
       "UKB_full_bayesian_0dot01              NaN         NaN   \n",
       "UKB_MC_dropout_quicknat               NaN         NaN   \n",
       "UKB_probabilistic_quicknat            NaN         NaN   \n",
       "UKB_hierarchical_quicknat             NaN         NaN   \n",
       "\n",
       "                              surface_distance_avg_spleen  \\\n",
       "TRAIN_full_bayesian_0dot01                       0.938857   \n",
       "TRAIN_hierarchical_quicknat                      0.966050   \n",
       "TRAIN_MC_dropout_quicknat                        0.969341   \n",
       "TRAIN_probabilistic_quicknat                     0.975707   \n",
       "TEST_full_bayesian_0dot01                        0.878335   \n",
       "TEST_MC_dropout_quicknat                         0.915783   \n",
       "TEST_probabilistic_quicknat                      0.875181   \n",
       "TEST_hierarchical_quicknat                       0.897130   \n",
       "UKB_full_bayesian_0dot01                              NaN   \n",
       "UKB_MC_dropout_quicknat                               NaN   \n",
       "UKB_probabilistic_quicknat                            NaN   \n",
       "UKB_hierarchical_quicknat                             NaN   \n",
       "\n",
       "                              surface_distance_avg_liver  \n",
       "TRAIN_full_bayesian_0dot01                      0.866480  \n",
       "TRAIN_hierarchical_quicknat                     0.928719  \n",
       "TRAIN_MC_dropout_quicknat                       0.940351  \n",
       "TRAIN_probabilistic_quicknat                    0.929685  \n",
       "TEST_full_bayesian_0dot01                       0.817338  \n",
       "TEST_MC_dropout_quicknat                        0.871014  \n",
       "TEST_probabilistic_quicknat                     0.827286  \n",
       "TEST_hierarchical_quicknat                      0.854920  \n",
       "UKB_full_bayesian_0dot01                             NaN  \n",
       "UKB_MC_dropout_quicknat                              NaN  \n",
       "UKB_probabilistic_quicknat                           NaN  \n",
       "UKB_hierarchical_quicknat                            NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_fetch = ['sncc', 'ged', 'iou_spleen', 'iou_liver', 'dice_spleen',\n",
    "       'dice_liver', 'surface_distance_avg_spleen', 'surface_distance_avg_liver']\n",
    "dicts = model_evaluation_matrics(model_report_paths, cols_to_fetch)\n",
    "df_model_eval = pd.DataFrame.from_dict(dicts)\n",
    "df_model_eval = df_model_eval.T\n",
    "# df_model_eval.columns = cols_to_fetch\n",
    "df_model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAIN_full_bayesian_0dot01      0.926283\n",
       "TRAIN_hierarchical_quicknat     0.941515\n",
       "TRAIN_MC_dropout_quicknat       0.943662\n",
       "TRAIN_probabilistic_quicknat    0.944800\n",
       "TEST_full_bayesian_0dot01       0.898814\n",
       "TEST_MC_dropout_quicknat        0.917508\n",
       "TEST_probabilistic_quicknat     0.899558\n",
       "TEST_hierarchical_quicknat      0.907924\n",
       "UKB_full_bayesian_0dot01             NaN\n",
       "UKB_MC_dropout_quicknat              NaN\n",
       "UKB_probabilistic_quicknat           NaN\n",
       "UKB_hierarchical_quicknat            NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_eval[['dice_spleen', 'dice_liver']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Process reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_full_bayesian_0dot01\n",
      "(155,)\n",
      "TRAIN_hierarchical_quicknat\n",
      "(155,)\n",
      "TRAIN_MC_dropout_quicknat\n",
      "(155,)\n",
      "TRAIN_probabilistic_quicknat\n",
      "(155,)\n",
      "model shape: (155, 57)\n",
      "model shape: (155, 57)\n",
      "model shape: (155, 57)\n",
      "model shape: (155, 57)\n",
      "model shape: (155, 17)\n",
      "dict_keys(['TRAIN_full_bayesian_0dot01', 'TRAIN_hierarchical_quicknat', 'TRAIN_MC_dropout_quicknat', 'TRAIN_probabilistic_quicknat', 'dataset_KORA_processed'])\n"
     ]
    }
   ],
   "source": [
    "dfs_train = {}\n",
    "common_vols = None\n",
    "\n",
    "for model, path in model_report_paths.items():\n",
    "    if 'dataset' in model:\n",
    "        continue\n",
    "    if 'TRAIN' not in model:\n",
    "        continue\n",
    "    print(model)\n",
    "    df = pd.read_csv(path)\n",
    "    df = rename(df)\n",
    "    \n",
    "    dfs_train[model] = df\n",
    "    vols = df[(df['iou_liver']>0.51) & (df['iou_liver'] != 1.0)].volume_id.values\n",
    "    if common_vols is None:\n",
    "        common_vols = vols\n",
    "    else:\n",
    "        common_vols = np.intersect1d(common_vols, vols)\n",
    "    print(common_vols.shape)\n",
    "\n",
    "df_dataset = pd.read_csv(model_report_paths['dataset_KORA_processed'])\n",
    "df_dataset = rename(df_dataset)\n",
    "dfs_train['dataset_KORA_processed']  = df_dataset\n",
    "\n",
    "for model, df in dfs_train.items():\n",
    "    if 'dataset' in model:\n",
    "        selected_feats = selected_dataset_feats\n",
    "    else:\n",
    "        selected_feats = selected_model_feats #+ ['iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised']\n",
    "     \n",
    "        \n",
    "    df = df[df.volume_id.isin(common_vols)][selected_feats]\n",
    "    df['seg_spleen_bmi_normalised'] = df['seg_spleen'] / df['bmi_numeric']\n",
    "    df['seg_liver_bmi_normalised'] = df['seg_liver'] / df['bmi_numeric']\n",
    "    df['age2'] = df['age'] ** 2\n",
    "    df['bmi2'] = df['bmi_numeric'] ** 2\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver', 'age', 'bmi_numeric','seg_liver_bmi_normalised', 'seg_spleen_bmi_normalised'])\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen_bmi_normalised', 'seg_liver_bmi_normalised'])\n",
    "    if 'dataset' not in model:\n",
    "        df['iou_dot_seg_spleen'] = df['iou_spleen'] * df['seg_spleen']\n",
    "        df['iou_dot_seg_liver'] = df['iou_liver'] * df['seg_liver']\n",
    "        df, _ =  z_score_column_normalise(df, ['iou_dot_seg_spleen', 'iou_dot_seg_liver'])\n",
    "        df, _ = z_score_column_normalise(df, ['0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
    "           '5_liver', '6_liver', '7_liver', '8_liver', '9_liver'])\n",
    "        df = normalise_iou(df)\n",
    "#         print(df[])\n",
    "    dfs_train[model] = df\n",
    "    print('model shape:', dfs_train[model].shape)\n",
    "\n",
    "## Change pre-diabetic state to diabetic\n",
    "for model, df in dfs_train.items():\n",
    "    df.loc[df['diabetes_status']==2, 'diabetes_status'] = 1\n",
    "    dfs_train[model] = df\n",
    "    dfs_train[model].to_csv(f'final_feats_TRAIN_{model}.csv', index=False)\n",
    "\n",
    "print(dfs_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_full_bayesian_0dot01\n",
      "(150,)\n",
      "TEST_MC_dropout_quicknat\n",
      "(150,)\n",
      "TEST_probabilistic_quicknat\n",
      "(150,)\n",
      "TEST_hierarchical_quicknat\n",
      "(150,)\n",
      "model shape: (150, 57)\n",
      "model shape: (150, 57)\n",
      "model shape: (150, 57)\n",
      "model shape: (150, 57)\n",
      "model shape: (150, 17)\n",
      "dict_keys(['TEST_full_bayesian_0dot01', 'TEST_MC_dropout_quicknat', 'TEST_probabilistic_quicknat', 'TEST_hierarchical_quicknat', 'dataset_KORA_processed'])\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "common_vols = None\n",
    "\n",
    "for model, path in model_report_paths.items():\n",
    "    if 'dataset' in model:\n",
    "        continue\n",
    "    if 'TEST' not in model:\n",
    "        continue\n",
    "    print(model)\n",
    "    df = pd.read_csv(path)\n",
    "    df = rename(df)\n",
    "    dfs[model] = df\n",
    "    vols = df[(df['iou_liver']>0.51) & (df['iou_liver'] != 1.0)].volume_id.values\n",
    "    if common_vols is None:\n",
    "        common_vols = vols\n",
    "    else:\n",
    "        common_vols = np.intersect1d(common_vols, vols)\n",
    "    print(common_vols.shape)\n",
    "\n",
    "df_dataset = pd.read_csv(model_report_paths['dataset_KORA_processed'])\n",
    "df_dataset = rename(df_dataset)\n",
    "dfs['dataset_KORA_processed']  = df_dataset\n",
    "\n",
    "for model, df in dfs.items():\n",
    "    if 'dataset' in model:\n",
    "        selected_feats = selected_dataset_feats\n",
    "    else:\n",
    "        selected_feats = selected_model_feats #+ ['iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised']\n",
    "     \n",
    "        \n",
    "    df = df[df.volume_id.isin(common_vols)][selected_feats]\n",
    "    df['seg_spleen_bmi_normalised'] = df['seg_spleen'] / df['bmi_numeric']\n",
    "    df['seg_liver_bmi_normalised'] = df['seg_liver'] / df['bmi_numeric']\n",
    "    df['age2'] = df['age'] ** 2\n",
    "    df['bmi2'] = df['bmi_numeric'] ** 2\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver', 'age', 'bmi_numeric','seg_liver_bmi_normalised', 'seg_spleen_bmi_normalised'])\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen_bmi_normalised', 'seg_liver_bmi_normalised'])\n",
    "    if 'dataset' not in model:\n",
    "        df['iou_dot_seg_spleen'] = df['iou_spleen'] * df['seg_spleen']\n",
    "        df['iou_dot_seg_liver'] = df['iou_liver'] * df['seg_liver']\n",
    "        df, _ =  z_score_column_normalise(df, ['iou_dot_seg_spleen', 'iou_dot_seg_liver'])\n",
    "        df, _ = z_score_column_normalise(df, ['0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
    "           '5_liver', '6_liver', '7_liver', '8_liver', '9_liver'])\n",
    "        df = normalise_iou(df)\n",
    "#         print(df[])\n",
    "    dfs[model] = df\n",
    "    print('model shape:', dfs[model].shape)\n",
    "\n",
    "## Change pre-diabetic state to diabetic\n",
    "for model, df in dfs.items():\n",
    "    df.loc[df['diabetes_status']==2, 'diabetes_status'] = 1\n",
    "    dfs[model] = df\n",
    "    dfs[model].to_csv(f'final_feats_TEST_{model}.csv', index=False)\n",
    "    \n",
    "print(dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UKB_full_bayesian_0dot01\n",
      "(14698,)\n",
      "UKB_MC_dropout_quicknat\n",
      "(13985,)\n",
      "UKB_probabilistic_quicknat\n",
      "(13982,)\n",
      "UKB_hierarchical_quicknat\n",
      "(13969,)\n",
      "model shape of UKB_full_bayesian_0dot01: (13969, 57)\n",
      "Index(['age', 'sex', 'bmi_numeric', '0_spleen', '1_spleen', '2_spleen',\n",
      "       '3_spleen', '4_spleen', '5_spleen', '6_spleen', '7_spleen', '8_spleen',\n",
      "       '9_spleen', '0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
      "       '5_liver', '6_liver', '7_liver', '8_liver', '9_liver', 'seg_liver',\n",
      "       'seg_spleen', 'iou_spleen', 'iou_liver', 'iou_mean', 'volume_id',\n",
      "       'diabetes_status', 'seg_spleen_bmi_normalised',\n",
      "       'seg_liver_bmi_normalised', 'age2', 'bmi2', 'seg_spleen_normalised',\n",
      "       'seg_liver_normalised', 'age_normalised', 'bmi_numeric_normalised',\n",
      "       'seg_spleen_bmi_normalised_normalised',\n",
      "       'seg_liver_bmi_normalised_normalised', 'iou_dot_seg_spleen',\n",
      "       'iou_dot_seg_liver', 'iou_dot_seg_spleen_normalised',\n",
      "       'iou_dot_seg_liver_normalised', '0_liver_normalised',\n",
      "       '1_liver_normalised', '2_liver_normalised', '3_liver_normalised',\n",
      "       '4_liver_normalised', '5_liver_normalised', '6_liver_normalised',\n",
      "       '7_liver_normalised', '8_liver_normalised', '9_liver_normalised',\n",
      "       'iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised'],\n",
      "      dtype='object')\n",
      "model shape of UKB_MC_dropout_quicknat: (13969, 57)\n",
      "Index(['age', 'sex', 'bmi_numeric', '0_spleen', '1_spleen', '2_spleen',\n",
      "       '3_spleen', '4_spleen', '5_spleen', '6_spleen', '7_spleen', '8_spleen',\n",
      "       '9_spleen', '0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
      "       '5_liver', '6_liver', '7_liver', '8_liver', '9_liver', 'seg_liver',\n",
      "       'seg_spleen', 'iou_spleen', 'iou_liver', 'iou_mean', 'volume_id',\n",
      "       'diabetes_status', 'seg_spleen_bmi_normalised',\n",
      "       'seg_liver_bmi_normalised', 'age2', 'bmi2', 'seg_spleen_normalised',\n",
      "       'seg_liver_normalised', 'age_normalised', 'bmi_numeric_normalised',\n",
      "       'seg_spleen_bmi_normalised_normalised',\n",
      "       'seg_liver_bmi_normalised_normalised', 'iou_dot_seg_spleen',\n",
      "       'iou_dot_seg_liver', 'iou_dot_seg_spleen_normalised',\n",
      "       'iou_dot_seg_liver_normalised', '0_liver_normalised',\n",
      "       '1_liver_normalised', '2_liver_normalised', '3_liver_normalised',\n",
      "       '4_liver_normalised', '5_liver_normalised', '6_liver_normalised',\n",
      "       '7_liver_normalised', '8_liver_normalised', '9_liver_normalised',\n",
      "       'iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised'],\n",
      "      dtype='object')\n",
      "model shape of UKB_probabilistic_quicknat: (13969, 57)\n",
      "Index(['age', 'sex', 'bmi_numeric', '0_spleen', '1_spleen', '2_spleen',\n",
      "       '3_spleen', '4_spleen', '5_spleen', '6_spleen', '7_spleen', '8_spleen',\n",
      "       '9_spleen', '0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
      "       '5_liver', '6_liver', '7_liver', '8_liver', '9_liver', 'seg_liver',\n",
      "       'seg_spleen', 'iou_spleen', 'iou_liver', 'iou_mean', 'volume_id',\n",
      "       'diabetes_status', 'seg_spleen_bmi_normalised',\n",
      "       'seg_liver_bmi_normalised', 'age2', 'bmi2', 'seg_spleen_normalised',\n",
      "       'seg_liver_normalised', 'age_normalised', 'bmi_numeric_normalised',\n",
      "       'seg_spleen_bmi_normalised_normalised',\n",
      "       'seg_liver_bmi_normalised_normalised', 'iou_dot_seg_spleen',\n",
      "       'iou_dot_seg_liver', 'iou_dot_seg_spleen_normalised',\n",
      "       'iou_dot_seg_liver_normalised', '0_liver_normalised',\n",
      "       '1_liver_normalised', '2_liver_normalised', '3_liver_normalised',\n",
      "       '4_liver_normalised', '5_liver_normalised', '6_liver_normalised',\n",
      "       '7_liver_normalised', '8_liver_normalised', '9_liver_normalised',\n",
      "       'iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised'],\n",
      "      dtype='object')\n",
      "model shape of UKB_hierarchical_quicknat: (13969, 57)\n",
      "Index(['age', 'sex', 'bmi_numeric', '0_spleen', '1_spleen', '2_spleen',\n",
      "       '3_spleen', '4_spleen', '5_spleen', '6_spleen', '7_spleen', '8_spleen',\n",
      "       '9_spleen', '0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
      "       '5_liver', '6_liver', '7_liver', '8_liver', '9_liver', 'seg_liver',\n",
      "       'seg_spleen', 'iou_spleen', 'iou_liver', 'iou_mean', 'volume_id',\n",
      "       'diabetes_status', 'seg_spleen_bmi_normalised',\n",
      "       'seg_liver_bmi_normalised', 'age2', 'bmi2', 'seg_spleen_normalised',\n",
      "       'seg_liver_normalised', 'age_normalised', 'bmi_numeric_normalised',\n",
      "       'seg_spleen_bmi_normalised_normalised',\n",
      "       'seg_liver_bmi_normalised_normalised', 'iou_dot_seg_spleen',\n",
      "       'iou_dot_seg_liver', 'iou_dot_seg_spleen_normalised',\n",
      "       'iou_dot_seg_liver_normalised', '0_liver_normalised',\n",
      "       '1_liver_normalised', '2_liver_normalised', '3_liver_normalised',\n",
      "       '4_liver_normalised', '5_liver_normalised', '6_liver_normalised',\n",
      "       '7_liver_normalised', '8_liver_normalised', '9_liver_normalised',\n",
      "       'iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised'],\n",
      "      dtype='object')\n",
      "model shape of dataset_UKB_processed: (7, 17)\n",
      "Index(['age', 'sex', 'bmi_numeric', 'volume_id', 'diabetes_status',\n",
      "       'seg_liver', 'seg_spleen', 'seg_spleen_bmi_normalised',\n",
      "       'seg_liver_bmi_normalised', 'age2', 'bmi2', 'seg_spleen_normalised',\n",
      "       'seg_liver_normalised', 'age_normalised', 'bmi_numeric_normalised',\n",
      "       'seg_spleen_bmi_normalised_normalised',\n",
      "       'seg_liver_bmi_normalised_normalised'],\n",
      "      dtype='object')\n",
      "dict_keys(['UKB_full_bayesian_0dot01', 'UKB_MC_dropout_quicknat', 'UKB_probabilistic_quicknat', 'UKB_hierarchical_quicknat', 'dataset_UKB_processed'])\n"
     ]
    }
   ],
   "source": [
    "dfs_ukb = {}\n",
    "common_vols = None\n",
    "\n",
    "for model, path in model_report_paths.items():\n",
    "    if 'dataset' in model:\n",
    "        continue\n",
    "    if 'UKB' not in model:\n",
    "        continue\n",
    "    print(model)\n",
    "    df = pd.read_csv(path)\n",
    "    df = rename(df)\n",
    "    df = df.fillna(0)\n",
    "    df.drop_duplicates(subset =\"volume_id\", inplace = True)\n",
    "    dfs_ukb[model] = df\n",
    "    vols = df[(df['iou_liver']>0.51) & (df['iou_spleen'] != 1.0) & (df['iou_liver'] != 1.0)].volume_id.values\n",
    "    if common_vols is None:\n",
    "        common_vols = vols\n",
    "    else:\n",
    "        common_vols = np.intersect1d(common_vols, vols)\n",
    "    print(common_vols.shape)\n",
    "\n",
    "df_dataset = pd.read_csv(model_report_paths['dataset_UKB_processed'])\n",
    "\n",
    "# common_vols = np.intersect1d(common_vols, df_dataset.volume_id.values)\n",
    "df_dataset = rename(df_dataset)\n",
    "\n",
    "dfs_ukb['dataset_UKB_processed']  = df_dataset\n",
    "\n",
    "for model, df in dfs_ukb.items():\n",
    "    if 'dataset' in model:\n",
    "        selected_feats = selected_dataset_feats\n",
    "        df = df[selected_feats]\n",
    "    else:\n",
    "        selected_feats = selected_model_feats #+ ['iou_spleen_normalised', 'iou_liver_normalised', 'iou_mean_normalised']\n",
    "        df = df[df.volume_id.isin(common_vols)][selected_feats]\n",
    "        \n",
    "    df['seg_spleen_bmi_normalised'] = df['seg_spleen'] / df['bmi_numeric']\n",
    "    df['seg_liver_bmi_normalised'] = df['seg_liver'] / df['bmi_numeric']\n",
    "    df['age2'] = df['age'] ** 2\n",
    "    df['bmi2'] = df['bmi_numeric'] ** 2\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver', 'age', 'bmi_numeric'])\n",
    "    df, normalised_cols = z_score_column_normalise(df, ['seg_spleen_bmi_normalised', 'seg_liver_bmi_normalised'])\n",
    "    if 'dataset' not in model:\n",
    "        df['iou_dot_seg_spleen'] = df['iou_spleen'] * df['seg_spleen']\n",
    "        df['iou_dot_seg_liver'] = df['iou_liver'] * df['seg_liver']\n",
    "        df, _ =  z_score_column_normalise(df, ['iou_dot_seg_spleen', 'iou_dot_seg_liver'])\n",
    "        df, _ = z_score_column_normalise(df, ['0_liver', '1_liver', '2_liver', '3_liver', '4_liver',\n",
    "       '5_liver', '6_liver', '7_liver', '8_liver', '9_liver'])\n",
    "        df = normalise_iou(df)\n",
    "    dfs_ukb[model] = df\n",
    "    print(f'model shape of {model}:', dfs_ukb[model].shape)\n",
    "    print(dfs_ukb[model].columns)\n",
    "# df_dataset = pd.read_csv(model_report_paths['dataset_KORA_processed'])\n",
    "# df_dataset = rename(df_dataset)\n",
    "# dfs['dataset_KORA_processed'] = df[df.volume_id.isin(common_vols)][selected_dataset_feats]\n",
    "# print(dfs['dataset_KORA_processed'].shape)\n",
    "\n",
    "## Change pre-diabetic state to diabetic\n",
    "for model, df in dfs_ukb.items():\n",
    "    df.loc[df['diabetes_status']==2, 'diabetes_status'] = 1\n",
    "    dfs_ukb[model] = df\n",
    "    dfs_ukb[model].to_csv(f'final_feats_UKB_{model}.csv', index=False)\n",
    "    \n",
    "print(dfs_ukb.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equations\n",
    "\n",
    "Eq-1: Diabetes_status = a0 +a1*age + a2*sex + a3*BMI\n",
    "\n",
    "Eq-2: Diabetes_status = a0 +a1*age + a2*sex + a3*BMI + a4*seg_<spleen|liver>\n",
    "\n",
    "Eq-3: Diabetes_status = a0 +a1*age + a2*sex + a3*BMI + a4*seg_<spleen|liver> + a5*iou_<spleen|liver>\n",
    "\n",
    "Eq-4: Diabetes_status = a0 +a1*age + a2*sex + a3*BMI + a4*(iou_<spleen|liver> * seg_<spleen|liver>)\n",
    "\n",
    "Eq-4: (Diabetes_status == a0 +a1*age + a2*sex + a3*BMI + a4*seg_<spleen|liver>) * iou_<spleen|liver>\n",
    "\n",
    "// Eq-5: Diabetes_status = a0 +a1*age + a2*sex + a3*BMI +  a4*seg_<spleen|liver>)i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group features (eq 1, eq 2, eq 3 and eq 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = [] #basic_feats\n",
    "# basic_feats = basic_feats\n",
    "# dicts = {}\n",
    "# anova_test_dicts = {}\n",
    "# global_kora_models = {}\n",
    "# # basic_feats = normalised_basic_feats\n",
    "# for model, df in dfs.items():\n",
    "# #     \n",
    "# #     df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "# #     df = df.fillna(0)\n",
    "\n",
    "#     dicts[model] = {}\n",
    "#     global_kora_models[model] = {}\n",
    "#     target_col = 'diabetes_status'\n",
    " \n",
    "# #   Equation 1 process\n",
    "#     p_values, statsmodel, y_yp = gradient_boosting_evaluations(basic_feats, df, target_col, ['sex'], True)\n",
    "# #     print(y_yp)\n",
    "#     auc_score, f1_score = auc_roc(y_yp, f'{model}_csv_features')\n",
    "#     dicts[model][target_col] = p_values\n",
    "#     dicts[model][target_col]['auc'] = auc_score\n",
    "#     dicts[model][target_col]['f1'] = f1_score\n",
    "# #     dicts, global_kora_models[model]['normal'] = aggregate_model_outputs(df, target_col, basic_feats, dicts, model, target_col)\n",
    "#     global_kora_models[model]['normal'] = statsmodel\n",
    "# #     for organ in ['spleen', 'liver']:\n",
    "#     organ = 'liver'\n",
    "# #     Equation 2 process\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised']\n",
    "#     p_values, statsmodel, y_yp = gradient_boosting_evaluations(feats, df, target_col, ['sex'], True)\n",
    "#     auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_with_seg_volumes')\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_volumes'] = p_values\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_volumes']['auc'] = auc_score\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_volumes']['f1'] = f1_score\n",
    "# #     dicts, global_kora_models[model][f'{organ}_seg'] = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_with_{organ}_seg_volumes')\n",
    "#     global_kora_models[model][f'{organ}_seg'] = statsmodel\n",
    "#     if 'dataset' in model:\n",
    "#         continue\n",
    "\n",
    "# #     Equation 3 process\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised', f'iou_{organ}']\n",
    "#     p_values, statsmodel, y_yp = gradient_boosting_evaluations(feats, df, target_col, ['sex'], True)\n",
    "#     auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_with_seg_iou')\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_and_iou'] = p_values\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_and_iou']['auc'] = auc_score\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_and_iou']['f1'] = f1_score\n",
    "# #     dicts, global_kora_models[model][f'{organ}_seg_iou'] = aggregate_model_outputs(df, target_col, feats, dicts, model,target_col+f'_with_{organ}_seg_and_iou')\n",
    "#     global_kora_models[model][f'{organ}_seg_iou'] = statsmodel\n",
    "# #     Equation 3.1 process\n",
    "#     feats = basic_feats + [f'seg_{organ}_normalised' , f'iou_dot_seg_{organ}_normalised']\n",
    "#     p_values, statsmodel, y_yp = gradient_boosting_evaluations(feats, df, target_col, ['sex'], True)\n",
    "#     auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_with_seg_dot_iou')\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_dot_iou'] = p_values\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_dot_iou']['auc'] = auc_score\n",
    "#     dicts[model][target_col+f'_with_{organ}_seg_dot_iou']['f1'] = f1_score\n",
    "# #     dicts, global_kora_models[model][f'{organ}_seg_dot_iou'] = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_with_{organ}_seg_dot_iou')\n",
    "#     global_kora_models[model][f'{organ}_seg_dot_iou'] = statsmodel\n",
    "\n",
    "\n",
    "# #     Equation 4 process\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised']\n",
    "#     p_values, statsmodel, y_yp = weighted_gradient_boosting_evaluations(df, target_col, feats, f'iou_{organ}')\n",
    "#     auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_with_seg_reg_iou')\n",
    "#     dicts[model][target_col+f'_with_{organ}_regularised_seg_volumes'] = p_values\n",
    "#     dicts[model][target_col+f'_with_{organ}_regularised_seg_volumes']['auc'] = auc_score\n",
    "#     dicts[model][target_col+f'_with_{organ}_regularised_seg_volumes']['f1'] = f1_score\n",
    "# #     dicts, global_kora_models[model][f'{organ}_seg_reg_iou'] = aggregate_model_outputs(df, target_col, feats,  dicts, model, target_col+f'_with_{organ}_regularised_seg_volumes',None,  f'iou_mean')\n",
    "#     global_kora_models[model][f'{organ}_seg_reg_iou'] =  statsmodel\n",
    "\n",
    "    \n",
    "# p_value_df_ka = df_from_nested_dicts(dicts).T\n",
    "# p_value_df_styler_ka = highlight_significance(p_value_df_ka, 0.05)\n",
    "# p_value_df_styler_ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p_value_df_ka' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0c69a2b7e886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp_value_df_ka\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p_value_df_ka' is not defined"
     ]
    }
   ],
   "source": [
    "p_value_df_ka[['auc' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = [] #basic_feats\n",
    "# dicts = {}\n",
    "# anova_test_dicts = {}\n",
    "# # basic_feats = normalised_basic_feats\n",
    "# for model, df in dfs_train.items():\n",
    "# #     \n",
    "# #     df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "# #     df = df.fillna(0)\n",
    "# #     print(model)\n",
    "# #     if 'UKB' not in model:\n",
    "# # #         print('dataset cannot be processed!')\n",
    "# #         continue\n",
    "\n",
    "    \n",
    "# #     print(df.columns)\n",
    "# #     break\n",
    "#     dicts[model] = {}\n",
    "#     k_mod = 'TEST' + model[5:]\n",
    "#     if 'dataset' in model:\n",
    "#         k_mod = model\n",
    "        \n",
    "#     print(k_mod)\n",
    "# #     continue\n",
    "#     target_col = 'diabetes_status'\n",
    "# #     try:\n",
    "# #     Equation 1 process\n",
    "# #     p_values, statsmodel, y_yp = discrete_group_feature_stats(basic_feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_csv_feats')\n",
    "#     dicts[model][target_col] = {} #p_values\n",
    "# #         dicts[model][target_col]['auc'] = auc_score\n",
    "# #         dicts[model][target_col]['f1'] = f1_score\n",
    "#     dicts, _ = aggregate_model_outputs(df, target_col, basic_feats, dicts, model, target_col, global_kora_models[k_mod]['normal'])\n",
    "\n",
    "# #     Equation 2 process\n",
    "# #     for organ in ['spleen', 'liver']:\n",
    "#     organ = 'liver'\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised']\n",
    "# #         p_values, statsmodel, y_yp = discrete_group_feature_stats(feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_seg')\n",
    "#     dicts[model][target_col+f'_{organ}_with_seg_volumes'] = {} #p_values\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_volumes']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_volumes']['f1'] = f1_score\n",
    "#     dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_{organ}_with_seg_volumes', global_kora_models[k_mod][f'{organ}_seg'])\n",
    "\n",
    "#     if 'dataset' in model:\n",
    "#         continue\n",
    "        \n",
    "# #     Equation 3 process\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised', f'iou_{organ}']\n",
    "# #         p_values, statsmodel, y_yp = discrete_group_feature_stats(feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_seg_iou')\n",
    "#     dicts[model][target_col+f'_{organ}_with_seg_and_iou'] = {} #p_values\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_and_iou']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_and_iou']['f1'] = f1_score\n",
    "#     dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_{organ}_with_seg_and_iou', global_kora_models[k_mod][f'{organ}_seg_iou'])\n",
    "\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised',   f'iou_dot_seg_{organ}_normalised']\n",
    "# #         p_values, statsmodel, y_yp = discrete_group_feature_stats(feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_seg_dot_iou')\n",
    "#     dicts[model][target_col+f'_{organ}_with_seg_dot_iou'] = {} #p_values\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_dot_iou']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_dot_iou']['f1'] = f1_score\n",
    "#     dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_{organ}_with_seg_dot_iou', global_kora_models[k_mod][f'{organ}_seg_dot_iou'])\n",
    "\n",
    "\n",
    "#     #     Equation 4.0 process\n",
    "#     feats = basic_feats + [ f'seg_{organ}_normalised']\n",
    "# #         p_values, statsmodel, y_yp = discrete_weighted_group_feats(df, target_col, feats, f'iou_mean')\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_csv_feats')\n",
    "#     dicts[model][target_col+f'_{organ}_seg_reg_iou'] = {} #p_values\n",
    "# #         dicts[model][target_col+f'_{organ}_seg_reg_iou']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_{organ}_seg_reg_iou']['f1'] = f1_score\n",
    "#     dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_{organ}_seg_reg_iou', global_kora_models[k_mod][f'{organ}_seg_reg_iou'], f'iou_{organ}')\n",
    "# # #     Equation 4.1 process\n",
    "# #     feats = basic_feats + [ 'seg_spleen_normalised']\n",
    "# #     p_values, statsmodel = discrete_weighted_group_feats(df, target_col, feats, 'iou_spleen')\n",
    "# #     dicts[model][target_col+'_reg_iou_spleen'] = p_values\n",
    "\n",
    "#     #     #     Equation 4.2 process\n",
    "#     #     feats = basic_feats + [ 'seg_liver_normalised']\n",
    "#     #     p_values, statsmodel = discrete_weighted_group_feats(df, target_col, feats, 'iou_liver')\n",
    "#     #     dicts[model][target_col+'_reg_iou_liver'] = p_values\n",
    "# #     except Exception as e:\n",
    "# #         print('ERRROR::', e)\n",
    "# #         continue\n",
    "\n",
    "# p_value_df_a = df_from_nested_dicts(dicts).T\n",
    "# p_value_df_styler_a = highlight_significance(p_value_df_a, 0.05)\n",
    "# p_value_df_styler_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_value_df_a[['v_auc' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = [] #basic_feats\n",
    "# dicts = {}\n",
    "# anova_test_dicts = {}\n",
    "# # basic_feats = normalised_basic_feats\n",
    "# for model, df in dfs_ukb.items():\n",
    "# #     \n",
    "# #     df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "#     df = df.fillna(0)\n",
    "#     print(model)\n",
    "#     if 'UKB' not in model:\n",
    "# #         print('dataset cannot be processed!')\n",
    "#         continue\n",
    "\n",
    "        \n",
    "#     dicts[model] = {}\n",
    "#     k_mod = 'TEST' + model[3:]\n",
    "#     if 'dataset' in model:\n",
    "#         k_mod = 'dataset_KORA_processed'\n",
    "#     print(k_mod)\n",
    "#     target_col = 'diabetes_status'\n",
    "\n",
    "# #     Equation 1 process\n",
    "# #     p_values, statsmodel, y_yp = discrete_group_feature_stats(basic_feats, df, target_col, ['sex'], True)\n",
    "# #     auc_score, f1_score = auc_roc(y_yp, f'{model}_csv_feats')\n",
    "#     dicts[model][target_col] = {} # p_values\n",
    "# #     dicts[model][target_col]['auc'] = auc_score\n",
    "# #     dicts[model][target_col]['f1'] = f1_score\n",
    "#     dicts, _ = aggregate_model_outputs(df, target_col, basic_feats, dicts, model, target_col, global_kora_models[k_mod]['normal'])\n",
    "    \n",
    "# #     Equation 2 process\n",
    "#     for organ in ['liver']:\n",
    "#         feats = basic_feats + [ f'seg_{organ}_normalised']\n",
    "# #         p_values, statsmodel, y_yp = discrete_group_feature_stats(feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_seg')\n",
    "#         dicts[model][target_col+f'_{organ}_with_seg_volumes'] = {} # p_values\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_volumes']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_{organ}_with_seg_volumes']['f1'] = f1_score\n",
    "#         dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_{organ}_with_seg_volumes', global_kora_models[k_mod][f'{organ}_seg'])\n",
    "\n",
    "#         if 'dataset' in model:\n",
    "#             continue\n",
    "            \n",
    "#         #     Equation 3 process\n",
    "#         feats = basic_feats + [ f'seg_{organ}_normalised', f'iou_{organ}']\n",
    "# #         p_values, statsmodel, y_yp = discrete_group_feature_stats(feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_with_seg_iou')\n",
    "#         dicts[model][target_col+f'_with_{organ}_seg_and_iou'] = {} # p_values\n",
    "# #         dicts[model][target_col+f'_with_{organ}_seg_and_iou']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_with_{organ}_seg_and_iou']['f1'] = f1_score\n",
    "#         dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model,target_col+f'_with_{organ}_seg_and_iou', global_kora_models[k_mod][f'{organ}_seg_iou'])\n",
    "#     #     global_kora_models[model][f'{organ}_seg_iou'] = statsmodel\n",
    "    \n",
    "#     #     Equation 3.1 process\n",
    "#         feats = basic_feats + [f'seg_{organ}_normalised', f'iou_dot_seg_{organ}_normalised']\n",
    "# #         p_values, statsmodel, y_yp = discrete_group_feature_stats(feats, df, target_col, ['sex'], True)\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_with_seg_dot_iou')\n",
    "#         dicts[model][target_col+f'_with_{organ}_seg_dot_iou'] = {} # p_values\n",
    "# #         dicts[model][target_col+f'_with_{organ}_seg_dot_iou']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_with_{organ}_seg_dot_iou']['f1'] = f1_score\n",
    "#         dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_with_{organ}_seg_dot_iou', global_kora_models[k_mod][f'{organ}_seg_dot_iou'])\n",
    "#     #     global_kora_models[model][f'{organ}_seg_dot_iou'] = statsmodel\n",
    "\n",
    "\n",
    "#         #     Equation 4.0 process\n",
    "#         feats = basic_feats + [ f'seg_{organ}_normalised']\n",
    "# #         p_values, statsmodel, y_yp = discrete_weighted_group_feats(df, target_col, feats, f'iou_{organ}')\n",
    "# #         auc_score, f1_score = auc_roc(y_yp, f'{model}_{organ}_csv_feats')\n",
    "#         dicts[model][target_col+f'_{organ}_seg_reg_iou'] = {} # p_values\n",
    "# #         dicts[model][target_col+f'_{organ}_seg_reg_iou']['auc'] = auc_score\n",
    "# #         dicts[model][target_col+f'_{organ}_seg_reg_iou']['f1'] = f1_score\n",
    "#         dicts, _ = aggregate_model_outputs(df, target_col, feats, dicts, model, target_col+f'_{organ}_seg_reg_iou', global_kora_models[k_mod][f'{organ}_seg_reg_iou'], f'iou_{organ}')\n",
    "\n",
    "\n",
    "# p_value_df = df_from_nested_dicts(dicts).T\n",
    "# # p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "# # p_value_df_styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_value_df[['v_auc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Coefficients  Standard Errors  t values  Probabilites\n",
      "0   958021.4964       212559.815     4.507           0.0\n",
      "1   -10016.2459         2701.111    -3.708           0.0\n",
      "2    43600.9470         5420.855     8.043           0.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-460f14aac38d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_feats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'diabetes_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mfeats_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_feature_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diabetes_status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatsmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_yp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_group_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mregression_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_yp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{model}_{target_col}_csv-feats'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_col\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_with_csv_feats'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "feats = basic_feats\n",
    "dicts = {}\n",
    "anova_test_dicts = {}\n",
    "for model, df in dfs_train.items():\n",
    "#     \n",
    "#     df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "#     df = df.fillna(0)\n",
    "\n",
    "        \n",
    "    dicts[model] = {}\n",
    "    target_cols = ['seg_liver']\n",
    "    for target_col in target_cols:\n",
    "#     #     Equation 1 process\n",
    "#         feats_string = make_feature_string(basic_feats, ['sex', 'diabetes_status'])\n",
    "#         p_values, statsmodel = normal_group_fit(df, target_col, feats_string)\n",
    "#         dicts[model][target_col] = p_values\n",
    "\n",
    "    #     Equation 2 process\n",
    "        feats = basic_feats + ['diabetes_status']\n",
    "        feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "        p_values, statsmodel, y_yp = normal_group_fit(df, target_col, feats_string, feats)\n",
    "        regression_plot(y_yp, f'{model}_{target_col}_csv-feats')\n",
    "        dicts[model][target_col+'_with_csv_feats'] = p_values\n",
    "\n",
    "        if 'dataset' in model:\n",
    "#             print('dataset cannot be processed!')\n",
    "            continue\n",
    "    \n",
    "    #     Equation 3 process\n",
    "        iou_feat = ['iou_liver']\n",
    "        feats = basic_feats + [ 'diabetes_status'] + iou_feat\n",
    "        feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "        p_values, statsmodel, y_yp = normal_group_fit(df, target_col, feats_string, feats)\n",
    "        regression_plot(y_yp, f'{model}_{target_col}_seg_iou')\n",
    "        dicts[model][target_col+'_with_seg_and_iou'] = p_values\n",
    "\n",
    "    #     Equation 4 process\n",
    "        feats = basic_feats + [ 'diabetes_status']\n",
    "        feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "        p_values, statsmodel, y_yp = weighted_group_feats(df, target_col, feats_string, iou_feat[0], feats)\n",
    "        regression_plot(y_yp, f'{model}_{target_col}_seg_reg_iou')\n",
    "        dicts[model][target_col+'_with_regularised_seg_volumes'] = p_values\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df.to_csv('to_seg.csv')\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value_df_styler = highlight_significance(p_value_df[['C(diabetes_status, Treatment)[T.1]', 'psuedo_r2']], 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = basic_feats\n",
    "dicts = {}\n",
    "anova_test_dicts = {}\n",
    "for model, df in dfs_ukb.items():\n",
    "#     \n",
    "#     df, normalised_cols = z_score_column_normalise(df, ['seg_spleen', 'seg_liver'])\n",
    "#     df = df.fillna(0)\n",
    "\n",
    "    \n",
    "\n",
    "    if 'UKB' not in model:\n",
    "#         print('dataset cannot be processed!')\n",
    "        continue\n",
    "        \n",
    "    dicts[model] = {}\n",
    "    target_cols = ['seg_liver']\n",
    "    for target_col in target_cols:\n",
    "    #     Equation 1 process\n",
    "        feats = basic_feats + ['diabetes_status']\n",
    "        feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "        p_values, statsmodel, y_yp = normal_group_fit(df, target_col, feats_string)\n",
    "#         regression_plot(y_yp, f'{model}_{target_col}')\n",
    "        dicts[model][target_col] = p_values\n",
    "\n",
    "#     #     Equation 2 process\n",
    "#         feats = basic_feats + ['diabetes_status']\n",
    "#         feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "#         p_values, statsmodel = normal_group_fit(df, target_col, feats_string)\n",
    "#         dicts[model][target_col+'_with_seg_volumes'] = p_values\n",
    "\n",
    "    #     Equation 3 process\n",
    "        if 'dataset' in model:\n",
    "            print('dataset cannot be processed!')\n",
    "            continue\n",
    "\n",
    "        iou_feat = ['iou_liver']\n",
    "        feats = basic_feats + [ 'diabetes_status'] + iou_feat\n",
    "        feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "        p_values, statsmodel, y_yp = normal_group_fit(df, target_col, feats_string)\n",
    "#         regression_plot(y_yp, f'{model}_{target_col}_seg_iou')\n",
    "        dicts[model][target_col+'_with_iou'] = p_values\n",
    "\n",
    "    #     Equation 4 process\n",
    "        feats = basic_feats + [ 'diabetes_status']\n",
    "        feats_string = make_feature_string(feats, ['sex', 'diabetes_status'])\n",
    "        p_values, statsmodel, y_yp = weighted_group_feats(df, target_col, feats_string, iou_feat[0])\n",
    "#         regression_plot(y_yp, f'{model}_{target_col}_seg_reg_iou')\n",
    "        dicts[model][target_col+'_with_regularised_seg_volumes'] = p_values\n",
    "\n",
    "p_value_df = df_from_nested_dicts(dicts).T\n",
    "p_value_df.to_csv('to_seg.csv')\n",
    "p_value_df_styler = highlight_significance(p_value_df, 0.05)\n",
    "p_value_df_styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tenv]",
   "language": "python",
   "name": "conda-env-tenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
